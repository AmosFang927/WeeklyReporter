from flask import Flask, jsonify, request
from datetime import datetime
import subprocess
import threading
import os
import sys
import time
import json
from concurrent.futures import ThreadPoolExecutor
import queue

app = Flask(__name__)

# è·å–æœåŠ¡åç§° - ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è·å–ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
SERVICE_NAME = os.environ.get('K_SERVICE', 'reporter-agent')

# å…¨å±€ä»»åŠ¡çŠ¶æ€ç®¡ç†
task_status = {
    "current_task": None,
    "task_history": [],
    "last_health_check": None,
    "server_start_time": datetime.now()
}

# ä»»åŠ¡é˜Ÿåˆ—å’Œçº¿ç¨‹æ± ç®¡ç†
task_queue = queue.Queue()
executor = ThreadPoolExecutor(max_workers=2)  # é™åˆ¶å¹¶å‘ä»»åŠ¡æ•°é‡

class TaskManager:
    def __init__(self):
        self.tasks = {}
        self.lock = threading.Lock()
    
    def create_task(self, task_id, command, parameters):
        with self.lock:
            self.tasks[task_id] = {
                "id": task_id,
                "status": "queued",
                "command": command,
                "parameters": parameters,
                "start_time": None,
                "end_time": None,
                "result": None,
                "progress": "Task queued"
            }
            return task_id
    
    def update_task(self, task_id, status, progress=None, result=None):
        with self.lock:
            if task_id in self.tasks:
                self.tasks[task_id]["status"] = status
                if progress:
                    self.tasks[task_id]["progress"] = progress
                if result:
                    self.tasks[task_id]["result"] = result
                if status == "running" and not self.tasks[task_id]["start_time"]:
                    self.tasks[task_id]["start_time"] = datetime.now()
                elif status in ["completed", "failed"]:
                    self.tasks[task_id]["end_time"] = datetime.now()
    
    def get_task(self, task_id):
        with self.lock:
            return self.tasks.get(task_id)
    
    def get_running_tasks(self):
        with self.lock:
            return [task for task in self.tasks.values() if task["status"] == "running"]

# å…¨å±€ä»»åŠ¡ç®¡ç†å™¨
task_manager = TaskManager()

@app.route("/", methods=["GET"])
@app.route("/health", methods=["GET"])
def health_check():
    """è¶…è½»é‡çº§å¥åº·æ£€æŸ¥ç«¯ç‚¹ - ä¼˜å…ˆå“åº”"""
    global task_status
    task_status["last_health_check"] = datetime.now()
    
    # æœ€å°åŒ–å“åº”ï¼Œç¡®ä¿å¿«é€Ÿè¿”å›
    return jsonify({"status": "healthy", "timestamp": datetime.now().isoformat()}), 200

@app.route("/health/detailed", methods=["GET"])
def detailed_health_check():
    """è¯¦ç»†å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    global task_status
    running_tasks = task_manager.get_running_tasks()
    
    return jsonify({
        "status": "healthy",
        "service": SERVICE_NAME,
        "timestamp": datetime.now().isoformat(),
        "version": "2.1.0",
        "uptime_seconds": (datetime.now() - task_status["server_start_time"]).total_seconds(),
        "running_tasks": len(running_tasks),
        "last_health_check": task_status["last_health_check"].isoformat() if task_status["last_health_check"] else None,
        "memory_info": {
            "available": True,  # ç®€åŒ–å†…å­˜æ£€æŸ¥
            "status": "ok"
        }
    })

@app.route("/liveness", methods=["GET"])
def liveness_probe():
    """ä¸“ç”¨å­˜æ´»æ¢é’ˆ - æœ€å¿«é€Ÿå“åº”"""
    return "OK", 200

@app.route("/readiness", methods=["GET"])
def readiness_probe():
    """å°±ç»ªæ¢é’ˆ - æ£€æŸ¥æœåŠ¡æ˜¯å¦å‡†å¤‡å¥½æ¥æ”¶è¯·æ±‚"""
    running_tasks = task_manager.get_running_tasks()
    if len(running_tasks) > 1:  # å¦‚æœæœ‰å¤ªå¤šä»»åŠ¡è¿è¡Œï¼Œå¯èƒ½ä¸å¤Ÿready
        return jsonify({"status": "not_ready", "reason": "too_many_running_tasks"}), 503
    return jsonify({"status": "ready"}), 200

@app.route("/run", methods=["POST"])
def run_weekly_reporter():
    """æ‰‹åŠ¨è§¦å‘WeeklyReporterä»»åŠ¡ - å®Œå…¨åŒæ­¥main.pyå‚æ•°"""
    try:
        # è·å–è¯·æ±‚å‚æ•°
        data = request.get_json() if request.is_json else {}
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤ªå¤šä»»åŠ¡åœ¨è¿è¡Œ
        running_tasks = task_manager.get_running_tasks()
        if len(running_tasks) >= 2:
            return jsonify({
                "status": "rejected",
                "message": "Too many tasks running. Please wait for current tasks to complete.",
                "running_tasks": len(running_tasks),
                "timestamp": datetime.now().isoformat()
            }), 429
        
        # ç”Ÿæˆä»»åŠ¡ID
        task_id = f"task_{int(time.time())}_{hash(str(data)) % 10000}"
        
        # =============================================================================
        # ğŸ“‹ å‚æ•°å¤„ç† - å®Œå…¨åŒæ­¥main.pyæ”¯æŒçš„å‚æ•°
        # =============================================================================
        
        # åŸºç¡€å‚æ•° - ä¸main.pyå®Œå…¨ä¸€è‡´
        api = data.get('api')                          # --api
        start_date = data.get('start_date')            # --start-date  
        end_date = data.get('end_date')                # --end-date
        days_ago = data.get('days_ago')                # --days-ago
        limit = data.get('limit')                      # --limit
        partner = data.get('partner')                  # --partner (åªæ”¯æŒå•æ•°å½¢å¼)
        output = data.get('output')                    # --output
        
        # åŠŸèƒ½å¼€å…³å‚æ•° - ä¸main.pyå®Œå…¨ä¸€è‡´
        api_only = data.get('api_only', False)         # --api-only
        convert_only = data.get('convert_only')        # --convert-only
        process_only = data.get('process_only')        # --process-only
        upload_only = data.get('upload_only', False)   # --upload-only
        save_json = data.get('save_json', True)        # --save-json
        upload_feishu = data.get('upload_feishu', True) # --upload-feishu
        test_feishu = data.get('test_feishu', False)   # --test-feishu
        send_email = data.get('send_email', True)      # --send-email
        self_email = data.get('self_email', False)     # --self-email
        no_email = data.get('no_email', False)         # --no-email
        test_email = data.get('test_email', False)     # --test-email
        start_scheduler = data.get('start_scheduler', False) # --start-scheduler
        run_scheduler_now = data.get('run_scheduler_now', False) # --run-scheduler-now
        verbose = data.get('verbose', False)           # --verbose
        
        # å¤„ç†ç›¸å¯¹æ—¥æœŸå‚æ•°
        if days_ago is not None:
            from datetime import timedelta
            target_date = (datetime.now() - timedelta(days=int(days_ago))).strftime('%Y-%m-%d')
            start_date = target_date
            end_date = target_date
            print(f"ğŸ“… [Cloud Scheduler] ä½¿ç”¨ç›¸å¯¹æ—¥æœŸ: {days_ago}å¤©å‰ = {target_date}")
            sys.stdout.flush()
        
        # =============================================================================
        # ğŸ”§ æ„å»ºå‘½ä»¤ - å®Œå…¨åŒæ­¥main.pyæ”¯æŒçš„å‚æ•°
        # =============================================================================
        cmd = ["python", "main.py"]
        
        # æ·»åŠ åŸºç¡€å‚æ•°
        if api:
            cmd.extend(["--api", api])
        if start_date:
            cmd.extend(["--start-date", start_date])
        if end_date:
            cmd.extend(["--end-date", end_date])
        if days_ago is not None:
            cmd.extend(["--days-ago", str(days_ago)])
        if limit:
            cmd.extend(["--limit", str(limit)])
        if partner:
            cmd.extend(["--partner", partner])
        if output:
            cmd.extend(["--output", output])
            
        # æ·»åŠ åŠŸèƒ½å¼€å…³å‚æ•°
        if api_only:
            cmd.append("--api-only")
        if convert_only:
            cmd.extend(["--convert-only", convert_only])
        if process_only:
            cmd.extend(["--process-only", process_only])
        if upload_only:
            cmd.append("--upload-only")
        if save_json:
            cmd.append("--save-json")
        if upload_feishu:
            cmd.append("--upload-feishu")
        if test_feishu:
            cmd.append("--test-feishu")
        if send_email:
            cmd.append("--send-email")
        if self_email:
            cmd.append("--self-email")
        if no_email:
            cmd.append("--no-email")
        if test_email:
            cmd.append("--test-email")
        if start_scheduler:
            cmd.append("--start-scheduler")
        if run_scheduler_now:
            cmd.append("--run-scheduler-now")
        if verbose:
            cmd.append("--verbose")
        
        # åˆ›å»ºä»»åŠ¡è®°å½•
        task_manager.create_task(task_id, " ".join(cmd), data)
        
        def run_task_with_monitoring():
            """å¸¦ç›‘æ§çš„ä»»åŠ¡æ‰§è¡Œå‡½æ•°"""
            env = os.environ.copy()
            env['PYTHONUNBUFFERED'] = '1'
            
            # å®šä¹‰è¿›åº¦ç›‘æ§
            import threading
            import time
            
            # ä½¿ç”¨å¯å˜å¯¹è±¡æ¥ç¡®ä¿åœ¨æ‰€æœ‰ä½œç”¨åŸŸä¸­éƒ½èƒ½ä¿®æ”¹
            monitor_status = {"active": True}
            
            def progress_monitor():
                """è¿›åº¦ç›‘æ§çº¿ç¨‹ï¼Œæ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡"""
                wait_time = 0
                while monitor_status["active"] and wait_time < 3300:  # 55åˆ†é’Ÿæ€»ç›‘æ§æ—¶é—´
                    time.sleep(300)  # ç­‰å¾…5åˆ†é’Ÿ
                    wait_time += 300
                    if monitor_status["active"]:
                        print(f"â±ï¸ [Cloud Scheduler] ä»»åŠ¡æ‰§è¡Œè¿›åº¦æ£€æŸ¥ (ID: {task_id}) - å·²è¿è¡Œ {wait_time//60} åˆ†é’Ÿ")
                        task_manager.update_task(task_id, "running", f"Task running for {wait_time//60} minutes...")
                        sys.stdout.flush()
            
            # å¯åŠ¨è¿›åº¦ç›‘æ§çº¿ç¨‹
            monitor_thread = threading.Thread(target=progress_monitor, daemon=True)
            monitor_thread.start()
            
            try:
                task_manager.update_task(task_id, "running", "Task started, initializing...")
                print(f"ğŸš€ [Cloud Scheduler] å¼€å§‹æ‰§è¡ŒWeeklyReporterä»»åŠ¡ (ID: {task_id})")
                print(f"ğŸ“‹ [Cloud Scheduler] æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
                print(f"ğŸ“‹ [Cloud Scheduler] æ‰§è¡Œå‚æ•°: {data}")
                sys.stdout.flush()
                
                # æ‰§è¡Œä»»åŠ¡ï¼Œè®¾ç½®åˆç†çš„èµ„æºé™åˆ¶å’Œè¯¦ç»†æ—¥å¿—
                task_manager.update_task(task_id, "running", "Executing main process...")
                print(f"ğŸš€ [Cloud Scheduler] å¼€å§‹æ‰§è¡Œä¸»ç¨‹åºï¼Œè®¾ç½®55åˆ†é’Ÿè¶…æ—¶ (ID: {task_id})")
                sys.stdout.flush()
                
                result = subprocess.run(
                    cmd, 
                    check=True, 
                    text=True,
                    env=env,
                    stdout=subprocess.PIPE,  # æ•è·è¾“å‡ºç”¨äºæ—¥å¿—è®°å½•
                    stderr=subprocess.STDOUT,  # åˆå¹¶é”™è¯¯åˆ°æ ‡å‡†è¾“å‡º
                    timeout=3540  # 59åˆ†é’Ÿè¶…æ—¶ï¼Œæœ€å¤§åŒ–åˆ©ç”¨Cloud Runçš„1å°æ—¶é™åˆ¶
                )
                
                # è¾“å‡ºæ‰§è¡Œç»“æœåˆ°æ—¥å¿—
                if result.stdout:
                    print(f"ğŸ“‹ [Cloud Scheduler] æ‰§è¡Œè¾“å‡º (ID: {task_id}):")
                    # åªè¾“å‡ºæœ€å500è¡Œï¼Œé¿å…æ—¥å¿—è¿‡é•¿
                    output_lines = result.stdout.strip().split('\n')
                    if len(output_lines) > 500:
                        print("... (çœç•¥å‰é¢çš„è¾“å‡º) ...")
                        for line in output_lines[-500:]:
                            print(f"   {line}")
                    else:
                        for line in output_lines:
                            print(f"   {line}")
                    sys.stdout.flush()
                
                # åœæ­¢è¿›åº¦ç›‘æ§
                monitor_status["active"] = False
                
                task_manager.update_task(task_id, "completed", "Task completed successfully", {
                    "return_code": result.returncode,
                    "success": True
                })
                print(f"âœ… [Cloud Scheduler] WeeklyReporteræ‰§è¡ŒæˆåŠŸ (ID: {task_id})")
                sys.stdout.flush()
                
            except subprocess.TimeoutExpired as e:
                # åœæ­¢è¿›åº¦ç›‘æ§
                monitor_status["active"] = False
                
                task_manager.update_task(task_id, "failed", "Task timed out after 55 minutes", {
                    "error": "timeout",
                    "message": str(e)
                })
                print(f"â° [Cloud Scheduler] WeeklyReporteræ‰§è¡Œè¶…æ—¶ (ID: {task_id}): {e}")
                print(f"ğŸ’¡ [Cloud Scheduler] å»ºè®®ï¼šæ£€æŸ¥APIè°ƒç”¨æ˜¯å¦å¡ä½ï¼Œè€ƒè™‘ä¼˜åŒ–æ•°æ®å¤„ç†é€»è¾‘")
                sys.stdout.flush()
            except subprocess.CalledProcessError as e:
                # åœæ­¢è¿›åº¦ç›‘æ§
                monitor_status["active"] = False
                
                # æ•è·è¿›ç¨‹é”™è¯¯çš„è¯¦ç»†è¾“å‡º
                error_output = ""
                if hasattr(e, 'stdout') and e.stdout:
                    error_output = e.stdout.strip()
                
                task_manager.update_task(task_id, "failed", f"Process failed with return code {e.returncode}", {
                    "error": "process_error",
                    "return_code": e.returncode,
                    "message": str(e),
                    "output": error_output
                })
                print(f"âŒ [Cloud Scheduler] WeeklyReporteræ‰§è¡Œå¤±è´¥ (ID: {task_id}): {e}")
                if error_output:
                    print(f"ğŸ“‹ [Cloud Scheduler] é”™è¯¯è¾“å‡º:")
                    # è¾“å‡ºæœ€å100è¡Œé”™è¯¯ä¿¡æ¯
                    error_lines = error_output.split('\n')
                    if len(error_lines) > 100:
                        print("... (çœç•¥å‰é¢çš„é”™è¯¯) ...")
                        for line in error_lines[-100:]:
                            print(f"   ERROR: {line}")
                    else:
                        for line in error_lines:
                            print(f"   ERROR: {line}")
                sys.stdout.flush()
            except Exception as e:
                # åœæ­¢è¿›åº¦ç›‘æ§
                monitor_status["active"] = False
                
                task_manager.update_task(task_id, "failed", f"Unexpected error: {str(e)}", {
                    "error": "unexpected",
                    "message": str(e)
                })
                print(f"âŒ [Cloud Scheduler] æ‰§è¡Œå¼‚å¸¸ (ID: {task_id}): {str(e)}")
                print(f"ğŸ” [Cloud Scheduler] å¼‚å¸¸ç±»å‹: {type(e).__name__}")
                sys.stdout.flush()
        
        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œä»»åŠ¡
        print(f"ğŸ“¨ [Cloud Scheduler] æ”¶åˆ°è°ƒåº¦è¯·æ±‚ (ID: {task_id}): {data}")
        sys.stdout.flush()
        
        future = executor.submit(run_task_with_monitoring)
        
        # =============================================================================
        # ğŸ“¤ å“åº”å‚æ•° - åªè¿”å›main.pyæ”¯æŒçš„å‚æ•°
        # =============================================================================
        response = {
            "status": "started",
            "task_id": task_id,
            "message": "WeeklyReporter task started in background",
            "timestamp": datetime.now().isoformat(),
            "command": " ".join(cmd),
            "parameters": {
                # åªåŒ…å«main.pyå®é™…æ”¯æŒçš„å‚æ•°
                "api": api,
                "start_date": start_date,
                "end_date": end_date,
                "days_ago": days_ago,
                "limit": limit,
                "partner": partner,
                "output": output,
                "api_only": api_only,
                "convert_only": convert_only,
                "process_only": process_only,
                "upload_only": upload_only,
                "save_json": save_json,
                "upload_feishu": upload_feishu,
                "test_feishu": test_feishu,
                "send_email": send_email,
                "self_email": self_email,
                "no_email": no_email,
                "test_email": test_email,
                "start_scheduler": start_scheduler,
                "run_scheduler_now": run_scheduler_now,
                "verbose": verbose
            },
            "estimated_duration": "15-30 minutes",
            "status_check_url": f"/task/{task_id}"
        }
        
        return jsonify(response)
        
    except Exception as e:
        error_msg = f"âŒ [Cloud Scheduler] è¯·æ±‚å¤„ç†å¤±è´¥: {str(e)}"
        print(error_msg)
        sys.stdout.flush()
        return jsonify({
            "status": "error",
            "message": str(e),
            "timestamp": datetime.now().isoformat()
        }), 500

@app.route("/task/<task_id>", methods=["GET"])
def get_task_status(task_id):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    task = task_manager.get_task(task_id)
    if not task:
        return jsonify({"error": "Task not found"}), 404
    
    # è®¡ç®—è¿è¡Œæ—¶é—´
    if task["start_time"]:
        if task["end_time"]:
            duration = (task["end_time"] - task["start_time"]).total_seconds()
        else:
            duration = (datetime.now() - task["start_time"]).total_seconds()
        task["duration_seconds"] = duration
    
    return jsonify(task)

@app.route("/tasks", methods=["GET"])
def list_tasks():
    """åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡"""
    limit = request.args.get('limit', 10, type=int)
    status_filter = request.args.get('status')
    
    with task_manager.lock:
        tasks = list(task_manager.tasks.values())
    
    # è¿‡æ»¤çŠ¶æ€
    if status_filter:
        tasks = [t for t in tasks if t["status"] == status_filter]
    
    # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
    tasks.sort(key=lambda x: x.get("start_time") or datetime.min, reverse=True)
    
    return jsonify({
        "tasks": tasks[:limit],
        "total": len(tasks),
        "filters": {"status": status_filter, "limit": limit}
    })

@app.route("/status", methods=["GET"])
def status():
    """æœåŠ¡çŠ¶æ€ç«¯ç‚¹"""
    running_tasks = task_manager.get_running_tasks()
    
    return jsonify({
        "status": "running",
        "service": SERVICE_NAME,
        "version": "2.1.0",
        "description": "Weekly reporting service for Involve Asia data - Enhanced Edition",
        "uptime_seconds": (datetime.now() - task_status["server_start_time"]).total_seconds(),
        "active_tasks": len(running_tasks),
        "endpoints": {
            "/": "Health check (lightweight)",
            "/health": "Health check (lightweight)",
            "/health/detailed": "Detailed health check",
            "/liveness": "Liveness probe",
            "/readiness": "Readiness probe",
            "/run": "Manual trigger (POST) - supports full parameters",
            "/task/<id>": "Get task status",
            "/tasks": "List all tasks",
            "/status": "Service status",
            "/timezone": "Timezone configuration info"
        },
        "supported_parameters": {
            "api": "API configuration choice: LisaidWebeye, LisaidByteC, IAByteC",
            "start_date": "YYYY-MM-DD format",
            "end_date": "YYYY-MM-DD format",
            "days_ago": "Number of days ago (integer, overrides start_date/end_date)",
            "limit": "Maximum number of records (integer)",
            "partner": "Single partner name (e.g., 'YueMeng', 'all')",
            "output": "Custom output filename",
            "api_only": "Only execute API data fetching (boolean)",
            "convert_only": "Only execute JSON to Excel conversion (string: JSON file path)",
            "process_only": "Only execute data processing (string: Excel/JSON file path)",
            "upload_only": "Only execute Feishu upload (boolean)",
            "save_json": "Save intermediate JSON file (boolean, default: true)",
            "upload_feishu": "Upload to Feishu (boolean, default: true)",
            "test_feishu": "Test Feishu API connection (boolean)",
            "send_email": "Send email reports (boolean, default: true)",
            "self_email": "Send email to default recipient group (boolean)",
            "no_email": "Don't send emails to any Partners (boolean)",
            "test_email": "Test email connection (boolean)",
            "start_scheduler": "Start scheduler service (boolean)",
            "run_scheduler_now": "Execute scheduler task immediately (boolean)",
            "verbose": "Show detailed logs (boolean)"
        },
        "last_health_check": task_status["last_health_check"].isoformat() if task_status["last_health_check"] else None,
        "timestamp": datetime.now().isoformat()
    })

@app.route("/test", methods=["GET"])
def test_endpoint():
    """æµ‹è¯•ç«¯ç‚¹ - æ˜¾ç¤ºå½“å‰ç¯å¢ƒä¿¡æ¯"""
    return jsonify({
        "status": "ok",
        "service": SERVICE_NAME,
        "version": "2.1.0",
        "environment": {
            "working_directory": os.getcwd(),
            "python_executable": os.path.realpath(os.path.dirname(__file__)),
            "available_files": [f for f in os.listdir(".") if f.endswith((".py", ".md", ".txt"))],
        },
        "timestamp": datetime.now().isoformat()
    })

@app.route("/test-logging", methods=["GET", "POST"])
def test_logging():
    """æµ‹è¯•æ—¥å¿—è¾“å‡ºç«¯ç‚¹ - ç”¨äºéªŒè¯Cloud Runæ—¥å¿—æ˜¯å¦æ­£å¸¸æ˜¾ç¤º"""
    try:
        print(f"ğŸ§ª [Test] å¼€å§‹æµ‹è¯•æ—¥å¿—è¾“å‡º")
        print(f"â° [Test] æµ‹è¯•æ—¶é—´: {datetime.now().isoformat()}")
        
        # æ£€æŸ¥ç¯å¢ƒ
        is_cloud_run = os.getenv('K_SERVICE') is not None
        print(f"ğŸŒ [Test] è¿è¡Œç¯å¢ƒ: {'Cloud Run' if is_cloud_run else 'Local'}")
        sys.stdout.flush()
        
        # æµ‹è¯•ä¸åŒç±»å‹çš„è¾“å‡º
        for i in range(3):
            print(f"ğŸ“ [Test] è¾“å‡ºæµ‹è¯• {i+1}/3")
            sys.stdout.flush()
        
        # æµ‹è¯•é”™è¯¯è¾“å‡º
        print("âŒ [Test] è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•é”™è¯¯è¾“å‡º", file=sys.stderr)
        sys.stderr.flush()
        
        print(f"âœ… [Test] æ—¥å¿—æµ‹è¯•å®Œæˆ")
        sys.stdout.flush()
        
        return jsonify({
            "status": "success",
            "message": "æ—¥å¿—æµ‹è¯•å®Œæˆï¼Œè¯·æ£€æŸ¥Cloud Runæ—¥å¿—æŸ¥çœ‹è¾“å‡º",
            "timestamp": datetime.now().isoformat(),
            "environment": "Cloud Run" if is_cloud_run else "Local"
        })
    except Exception as e:
        error_msg = f"âŒ [Test] æ—¥å¿—æµ‹è¯•å¤±è´¥: {str(e)}"
        print(error_msg)
        sys.stdout.flush()
        return jsonify({
            "status": "error",
            "message": str(e),
            "timestamp": datetime.now().isoformat()
        }), 500

@app.route("/timezone", methods=["GET"])
def timezone_info():
    """æ—¶åŒºä¿¡æ¯ç«¯ç‚¹ - æ£€æŸ¥åº”ç”¨ç¨‹åºæ—¶åŒºé…ç½®"""
    try:
        import os
        from datetime import datetime
        from zoneinfo import ZoneInfo
        
        # å°è¯•å¯¼å…¥åº”ç”¨ç¨‹åºçš„æ—¶åŒºå·¥å…·
        try:
            from utils.logger import get_timezone_info, get_timezone_aware_time
            logger_available = True
        except ImportError:
            logger_available = False
        
        # æ”¶é›†æ—¶åŒºä¿¡æ¯
        utc_time = datetime.now(ZoneInfo('UTC'))
        singapore_time = datetime.now(ZoneInfo('Asia/Singapore'))
        system_time = datetime.now()
        
        timezone_data = {
            "status": "success",
            "environment": {
                "tz_env_var": os.getenv('TZ', 'NOT_SET'),
                "k_service": os.getenv('K_SERVICE', 'NOT_SET'),
                "is_cloud_run": bool(os.getenv('K_SERVICE'))
            },
            "times": {
                "utc": {
                    "timestamp": utc_time.isoformat(),
                    "formatted": utc_time.strftime('%Y-%m-%d %H:%M:%S %Z'),
                    "timezone": "UTC"
                },
                "singapore": {
                    "timestamp": singapore_time.isoformat(),
                    "formatted": singapore_time.strftime('%Y-%m-%d %H:%M:%S %Z'),
                    "timezone": "Asia/Singapore",
                    "utc_offset": singapore_time.strftime('%z')
                },
                "system": {
                    "timestamp": system_time.isoformat(),
                    "formatted": system_time.strftime('%Y-%m-%d %H:%M:%S'),
                    "timezone": "SYSTEM_DEFAULT"
                }
            },
            "application_logger": {
                "available": logger_available
            },
            "timestamp": datetime.now().isoformat()
        }
        
        # å¦‚æœloggerå¯ç”¨ï¼Œæ·»åŠ è¯¦ç»†ä¿¡æ¯
        if logger_available:
            try:
                logger_info = get_timezone_info()
                timezone_data["application_logger"].update({
                    "timezone": logger_info['timezone'],
                    "current_time": logger_info['current_time'],
                    "formatted_time": logger_info['formatted_time'],
                    "utc_offset": logger_info['utc_offset']
                })
            except Exception as e:
                timezone_data["application_logger"]["error"] = str(e)
        
        # é…ç½®éªŒè¯
        tz_env = os.getenv('TZ')
        timezone_data["validation"] = {
            "tz_env_correct": tz_env == 'Asia/Singapore',
            "logger_available": logger_available,
            "recommendations": []
        }
        
        if tz_env != 'Asia/Singapore':
            timezone_data["validation"]["recommendations"].append("è®¾ç½®ç¯å¢ƒå˜é‡ TZ=Asia/Singapore")
        
        if not logger_available:
            timezone_data["validation"]["recommendations"].append("æ£€æŸ¥utils.loggeræ¨¡å—æ˜¯å¦æ­£ç¡®å¯¼å…¥")
        
        return jsonify(timezone_data)
        
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": str(e),
            "timestamp": datetime.now().isoformat()
        }), 500

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8080))
    print(f"ğŸš€ å¯åŠ¨ WeeklyReporter Web Server v2.1.0")
    print(f"ğŸ“¡ ç«¯å£: {port}")
    print(f"ğŸ”§ æœ€å¤§å¹¶å‘ä»»åŠ¡: 2")
    print(f"â° ä»»åŠ¡è¶…æ—¶: 55åˆ†é’Ÿ")
    print(f"ğŸ¥ å¥åº·æ£€æŸ¥ç«¯ç‚¹: /health (è½»é‡), /health/detailed (è¯¦ç»†)")
    print(f"ğŸ’“ å­˜æ´»æ¢é’ˆ: /liveness")
    print(f"âœ… å°±ç»ªæ¢é’ˆ: /readiness")
    sys.stdout.flush()
    
    app.run(host="0.0.0.0", port=port, debug=False, threaded=True) 