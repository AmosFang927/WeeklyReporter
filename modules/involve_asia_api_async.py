#!/usr/bin/env python3
"""
Involve Asia API å¼‚æ­¥æ¨¡å—
ä½¿ç”¨ httpx å’Œ asyncio å®ç°é«˜æ€§èƒ½å¼‚æ­¥æ•°æ®è·å–
æ”¯æŒå¹¶å‘åˆ†é¡µè¯·æ±‚ï¼Œæ˜¾è‘—æå‡APIè°ƒç”¨æ€§èƒ½
"""

import httpx
import asyncio
import json
import time
import os
import sys
from datetime import datetime
from typing import Optional, Dict, List, Tuple, Any
from utils.logger import print_step
import config

# é‡ç”¨ç°æœ‰çš„ResourceMonitorç±»
from modules.involve_asia_api import ResourceMonitor

class AsyncInvolveAsiaAPI:
    """Involve Asia APIå¼‚æ­¥å®¢æˆ·ç«¯"""
    
    def __init__(self, api_secret=None, api_key=None):
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼æˆ–ä¼ å…¥çš„å€¼
        self.api_secret = api_secret or config.INVOLVE_ASIA_API_SECRET
        self.api_key = api_key or config.INVOLVE_ASIA_API_KEY
        
        # APIç«¯ç‚¹
        self.auth_url = config.INVOLVE_ASIA_AUTH_URL
        self.conversions_url = config.INVOLVE_ASIA_CONVERSIONS_URL
        
        # è®¤è¯token
        self.token = None
        
        # èµ„æºç›‘æ§å™¨
        self.resource_monitor = ResourceMonitor()
        
        # è·³è¿‡çš„é¡µé¢è®°å½•
        self.skipped_pages = []
        
        # è¯·æ±‚é…ç½®
        self.request_timeout = getattr(config, 'REQUEST_TIMEOUT', 30)
        self.max_retries = getattr(config, 'MAX_RETRY_ATTEMPTS', 5)
        self.request_delay = getattr(config, 'REQUEST_DELAY', 0.5)
        
        # å¹¶å‘é…ç½®
        self.max_concurrent_requests = getattr(config, 'MAX_CONCURRENT_REQUESTS', 5)
        self.semaphore = None
        
        # HTTPå®¢æˆ·ç«¯é…ç½®
        self.client_config = {
            'timeout': httpx.Timeout(self.request_timeout),
            'limits': httpx.Limits(
                max_keepalive_connections=10,
                max_connections=20,
                keepalive_expiry=30
            ),
            'follow_redirects': True
        }
    
    async def authenticate(self) -> bool:
        """æ‰§è¡ŒAPIè®¤è¯"""
        print_step("å¼‚æ­¥è®¤è¯", "æ­£åœ¨æ‰§è¡ŒAPIè®¤è¯...")
        
        headers = {"Accept": "application/json"}
        data = {
            "secret": self.api_secret,
            "key": self.api_key
        }
        
        try:
            async with httpx.AsyncClient(**self.client_config) as client:
                response = await client.post(
                    self.auth_url,
                    headers=headers,
                    data=data
                )
                response.raise_for_status()
                
                result = response.json()
                
                if "data" in result and "token" in result["data"]:
                    self.token = result["data"]["token"]
                    token_preview = self.token[:8] + "..." if len(self.token) > 8 else self.token
                    print_step("è®¤è¯æˆåŠŸ", f"è·å¾—Token: {token_preview}")
                    return True
                else:
                    print_step("è®¤è¯å¤±è´¥", f"å“åº”ç»“æ„ä¸ç¬¦åˆé¢„æœŸ: {result}")
                    return False
                    
        except httpx.RequestError as e:
            print_step("è®¤è¯å¤±è´¥", f"è¯·æ±‚é”™è¯¯: {str(e)}")
            return False
        except json.JSONDecodeError as e:
            print_step("è®¤è¯å¤±è´¥", f"JSONè§£æé”™è¯¯: {str(e)}")
            return False
        except Exception as e:
            print_step("è®¤è¯å¤±è´¥", f"æœªçŸ¥é”™è¯¯: {str(e)}")
            return False
    
    async def _make_single_request(self, client: httpx.AsyncClient, page: int, 
                                 start_date: str, end_date: str, currency: str,
                                 api_label: str = "") -> Tuple[Optional[Dict], bool, int]:
        """å‘é€å•ä¸ªé¡µé¢è¯·æ±‚"""
        headers = {
            "Accept": "application/json",
            "Authorization": f"Bearer {self.token}"
        }
        
        data = {
            "page": str(page),
            "limit": str(config.DEFAULT_PAGE_LIMIT),
            "start_date": start_date,
            "end_date": end_date,
            "filters[preferred_currency]": currency
        }
        
        max_retries = self.max_retries
        retry_count = 0
        
        while retry_count <= max_retries:
            try:
                if retry_count > 0:
                    wait_time = min(60, 10 * retry_count)
                    print(f"   ğŸ”„ ç¬¬{page}é¡µç¬¬{retry_count}æ¬¡é‡è¯•ï¼Œç­‰å¾…{wait_time}ç§’...")
                    await asyncio.sleep(wait_time)
                
                # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°é‡
                async with self.semaphore:
                    response = await client.post(
                        self.conversions_url,
                        headers=headers,
                        data=data
                    )
                    
                    # å¤„ç†429é”™è¯¯(é¢‘ç‡é™åˆ¶)
                    if response.status_code == 429:
                        retry_count += 1
                        print(f"   âš ï¸  ç¬¬{page}é¡µé‡åˆ°é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾…{config.RATE_LIMIT_DELAY}ç§’åé‡è¯•...")
                        await asyncio.sleep(config.RATE_LIMIT_DELAY)
                        continue
                    
                    response.raise_for_status()
                    result = response.json()
                    
                    if "data" not in result:
                        print_step("æ•°æ®è·å–å¤±è´¥", f"ç¬¬{page}é¡µå“åº”ä¸­æ²¡æœ‰dataå­—æ®µ: {result}")
                        retry_count += 1
                        continue
                    
                    # è¯·æ±‚æˆåŠŸ
                    return result, True, page
                    
            except httpx.TimeoutException as e:
                retry_count += 1
                print_step("è¯·æ±‚è¶…æ—¶", f"ç¬¬{page}é¡µè¯·æ±‚è¶…æ—¶ï¼ˆç¬¬{retry_count}æ¬¡é‡è¯•ï¼‰: {str(e)}")
                if retry_count <= max_retries:
                    self.resource_monitor.print_resource_status(f"ç¬¬{page}é¡µè¶…æ—¶é‡è¯•{retry_count}")
                
            except httpx.RequestError as e:
                retry_count += 1
                print_step("ç½‘ç»œé”™è¯¯", f"ç¬¬{page}é¡µè¯·æ±‚é”™è¯¯ï¼ˆç¬¬{retry_count}æ¬¡é‡è¯•ï¼‰: {str(e)}")
                if retry_count <= max_retries:
                    self.resource_monitor.print_resource_status(f"ç¬¬{page}é¡µç½‘ç»œé”™è¯¯é‡è¯•{retry_count}")
                
            except json.JSONDecodeError as e:
                retry_count += 1
                print_step("è§£æé”™è¯¯", f"ç¬¬{page}é¡µJSONè§£æé”™è¯¯ï¼ˆç¬¬{retry_count}æ¬¡é‡è¯•ï¼‰: {str(e)}")
                if retry_count <= max_retries:
                    self.resource_monitor.print_resource_status(f"ç¬¬{page}é¡µè§£æé”™è¯¯é‡è¯•{retry_count}")
            
            except Exception as e:
                retry_count += 1
                print_step("æœªçŸ¥é”™è¯¯", f"ç¬¬{page}é¡µæœªçŸ¥é”™è¯¯ï¼ˆç¬¬{retry_count}æ¬¡é‡è¯•ï¼‰: {str(e)}")
                if retry_count <= max_retries:
                    self.resource_monitor.print_resource_status(f"ç¬¬{page}é¡µæœªçŸ¥é”™è¯¯é‡è¯•{retry_count}")
            
            # æ·»åŠ é‡è¯•å»¶è¿Ÿ
            if retry_count <= max_retries:
                await asyncio.sleep(self.request_delay)
        
        # é‡è¯•æ¬¡æ•°ç”¨å®Œï¼Œè¿”å›å¤±è´¥
        return None, False, page
    
    async def _fetch_pages_concurrently(self, pages: List[int], start_date: str, 
                                      end_date: str, currency: str, api_label: str = "") -> List[Tuple]:
        """å¹¶å‘è·å–å¤šä¸ªé¡µé¢"""
        print_step("å¹¶å‘è¯·æ±‚", f"{api_label}å¼€å§‹å¹¶å‘è·å– {len(pages)} é¡µæ•°æ®...")
        
        # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°é‡
        self.semaphore = asyncio.Semaphore(self.max_concurrent_requests)
        
        async with httpx.AsyncClient(**self.client_config) as client:
            # åˆ›å»ºæ‰€æœ‰é¡µé¢çš„è¯·æ±‚ä»»åŠ¡
            tasks = [
                self._make_single_request(client, page, start_date, end_date, currency, api_label)
                for page in pages
            ]
            
            # å¹¶å‘æ‰§è¡Œæ‰€æœ‰è¯·æ±‚
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†ç»“æœ
            successful_results = []
            failed_pages = []
            
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    failed_pages.append(pages[i])
                    print_step("é¡µé¢å¼‚å¸¸", f"ç¬¬{pages[i]}é¡µå‘ç”Ÿå¼‚å¸¸: {str(result)}")
                elif result[1]:  # æˆåŠŸ
                    successful_results.append(result)
                else:  # å¤±è´¥
                    failed_pages.append(result[2])
            
            if failed_pages:
                self.skipped_pages.extend(failed_pages)
                print_step("é¡µé¢è·³è¿‡", f"è·³è¿‡å¤±è´¥é¡µé¢: {failed_pages}")
            
            print_step("å¹¶å‘å®Œæˆ", f"{api_label}å¹¶å‘è¯·æ±‚å®Œæˆï¼ŒæˆåŠŸ: {len(successful_results)}, å¤±è´¥: {len(failed_pages)}")
            return successful_results
    
    async def get_conversions_async(self, start_date: str, end_date: str, 
                                  currency: Optional[str] = None, api_name: Optional[str] = None) -> Optional[Dict]:
        """å¼‚æ­¥è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´çš„æ‰€æœ‰conversionæ•°æ®"""
        if not self.token:
            print_step("æ•°æ®è·å–å¤±è´¥", "æ²¡æœ‰æœ‰æ•ˆçš„è®¤è¯token")
            return None
        
        currency = currency or config.PREFERRED_CURRENCY
        api_label = f"[{api_name}] " if api_name else ""
        print_step("å¼‚æ­¥æ•°æ®è·å–", f"{api_label}å¼€å§‹å¼‚æ­¥è·å–è½¬æ¢æ•°æ® ({start_date} åˆ° {end_date})")
        
        # æ˜¾ç¤ºåˆå§‹èµ„æºçŠ¶æ€
        self.resource_monitor.print_resource_status(f"{api_label}å¼‚æ­¥æ•°æ®è·å–å¼€å§‹")
        
        all_conversions = []
        total_count = 0
        total_pages = 0
        pages_fetched = 0
        
        # æ­¥éª¤1: è·å–ç¬¬ä¸€é¡µä»¥ç¡®å®šæ€»é¡µæ•°
        print_step("è·å–å…ƒæ•°æ®", f"{api_label}è·å–ç¬¬ä¸€é¡µä»¥ç¡®å®šæ€»é¡µæ•°...")
        
        first_page_results = await self._fetch_pages_concurrently(
            [1], start_date, end_date, currency, api_label
        )
        
        if not first_page_results:
            print_step("æ•°æ®è·å–å¤±è´¥", f"{api_label}æ— æ³•è·å–ç¬¬ä¸€é¡µæ•°æ®")
            return None
        
        first_result, _, _ = first_page_results[0]
        data_obj = first_result["data"]
        
        if isinstance(data_obj, dict):
            first_page_data = data_obj.get("data", [])
            limit = data_obj.get("limit", config.DEFAULT_PAGE_LIMIT)
            total_count = data_obj.get("count", 0)
            
            # è®¡ç®—æ€»é¡µæ•°
            if total_count > 0:
                total_pages = (total_count + limit - 1) // limit
            
            all_conversions.extend(first_page_data)
            pages_fetched = 1
            
            print_step("å…ƒæ•°æ®è·å–", f"{api_label}æ€»è®°å½•æ•°: {total_count}, æ€»é¡µæ•°: {total_pages}")
            
            # æ£€æŸ¥è®°å½•æ•°é™åˆ¶
            if config.MAX_RECORDS_LIMIT is not None and total_count > config.MAX_RECORDS_LIMIT:
                actual_pages = (config.MAX_RECORDS_LIMIT + limit - 1) // limit
                total_pages = min(total_pages, actual_pages)
                print_step("è®°å½•é™åˆ¶", f"{api_label}åº”ç”¨è®°å½•æ•°é™åˆ¶ï¼Œè°ƒæ•´é¡µæ•°åˆ°: {total_pages}")
        else:
            # æ—§æ ¼å¼å…¼å®¹å¤„ç†
            first_page_data = first_result["data"] if isinstance(first_result["data"], list) else []
            all_conversions.extend(first_page_data)
            pages_fetched = 1
            total_pages = 10  # é»˜è®¤å‡è®¾æœ‰æ›´å¤šé¡µé¢
        
        # æ­¥éª¤2: å¦‚æœæœ‰æ›´å¤šé¡µé¢ï¼Œå¹¶å‘è·å–
        if total_pages > 1:
            remaining_pages = list(range(2, min(total_pages + 1, 101)))  # æœ€å¤šè·å–100é¡µé¿å…æ— é™è¯·æ±‚
            
            # æ£€æŸ¥è®°å½•æ•°é™åˆ¶
            if config.MAX_RECORDS_LIMIT is not None:
                max_pages = (config.MAX_RECORDS_LIMIT + limit - 1) // limit
                remaining_pages = [p for p in remaining_pages if p <= max_pages]
            
            if remaining_pages:
                print_step("å¹¶å‘ç­–ç•¥", f"{api_label}å°†å¹¶å‘è·å–å‰©ä½™ {len(remaining_pages)} é¡µæ•°æ®")
                
                # åˆ†æ‰¹å¹¶å‘å¤„ç†ï¼Œé¿å…ä¸€æ¬¡æ€§å‘é€å¤ªå¤šè¯·æ±‚
                batch_size = min(self.max_concurrent_requests * 2, 10)  # æ¯æ‰¹æœ€å¤š10é¡µ
                
                for i in range(0, len(remaining_pages), batch_size):
                    batch_pages = remaining_pages[i:i + batch_size]
                    print_step("æ‰¹æ¬¡å¤„ç†", f"{api_label}å¤„ç†ç¬¬ {i//batch_size + 1} æ‰¹ï¼Œé¡µé¢: {batch_pages}")
                    
                    batch_results = await self._fetch_pages_concurrently(
                        batch_pages, start_date, end_date, currency, api_label
                    )
                    
                    # å¤„ç†æ‰¹æ¬¡ç»“æœ
                    for result, success, page in batch_results:
                        if success and result:
                            data_obj = result["data"]
                            
                            if isinstance(data_obj, dict):
                                page_data = data_obj.get("data", [])
                                all_conversions.extend(page_data)
                                pages_fetched += 1
                                
                                print(f"   {api_label}ğŸ“Š ç¬¬ {page} é¡µ: è·å–åˆ° {len(page_data)} æ¡è®°å½•")
                            else:
                                # æ—§æ ¼å¼å…¼å®¹
                                page_data = result["data"] if isinstance(result["data"], list) else []
                                all_conversions.extend(page_data)
                                pages_fetched += 1
                    
                    # æ£€æŸ¥è®°å½•æ•°é™åˆ¶
                    if config.MAX_RECORDS_LIMIT is not None and len(all_conversions) >= config.MAX_RECORDS_LIMIT:
                        all_conversions = all_conversions[:config.MAX_RECORDS_LIMIT]
                        print_step("è®°å½•é™åˆ¶", f"{api_label}å·²è¾¾åˆ°è®°å½•æ•°é™åˆ¶ ({config.MAX_RECORDS_LIMIT} æ¡)ï¼Œåœæ­¢è·å–")
                        break
                    
                    # æ‰¹æ¬¡é—´æ·»åŠ çŸ­æš‚å»¶è¿Ÿ
                    if i + batch_size < len(remaining_pages):
                        await asyncio.sleep(self.request_delay)
        
        # æ˜¾ç¤ºæœ€ç»ˆèµ„æºçŠ¶æ€
        self.resource_monitor.print_resource_status(f"{api_label}å¼‚æ­¥æ•°æ®è·å–å®Œæˆ")
        
        if all_conversions:
            # æ„é€ å®Œæ•´ç»“æœ
            result = {
                "status": "success",
                "message": "Success",
                "data": {
                    "page": 1,
                    "limit": config.DEFAULT_PAGE_LIMIT,
                    "count": total_count or len(all_conversions),
                    "total_pages": total_pages,
                    "pages_fetched": pages_fetched,
                    "skipped_pages": self.skipped_pages,
                    "current_page_count": len(all_conversions),
                    "data": all_conversions,
                    "async_mode": True,
                    "concurrent_requests": self.max_concurrent_requests
                }
            }
            
            success_msg = f"{api_label}å¼‚æ­¥è·å–æˆåŠŸ: {len(all_conversions)} æ¡è½¬æ¢è®°å½•ï¼Œå…± {pages_fetched} é¡µ"
            if self.skipped_pages:
                success_msg += f"ï¼Œè·³è¿‡ {len(self.skipped_pages)} é¡µ: {self.skipped_pages}"
            
            print_step("å¼‚æ­¥è·å–æˆåŠŸ", success_msg)
            return result
        else:
            print_step("æ•°æ®è·å–å¤±è´¥", f"{api_label}æ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®")
            return None
    
    def get_conversions(self, start_date: str, end_date: str, 
                       currency: Optional[str] = None, api_name: Optional[str] = None) -> Optional[Dict]:
        """åŒæ­¥åŒ…è£…å™¨ï¼Œè¿è¡Œå¼‚æ­¥è·å–å‡½æ•°"""
        return asyncio.run(self.get_conversions_async(start_date, end_date, currency, api_name))
    
    async def get_conversions_default_range_async(self, currency: Optional[str] = None) -> Optional[Dict]:
        """ä½¿ç”¨é»˜è®¤æ—¥æœŸèŒƒå›´å¼‚æ­¥è·å–æ•°æ®"""
        start_date, end_date = config.get_default_date_range()
        return await self.get_conversions_async(start_date, end_date, currency)
    
    def get_conversions_default_range(self, currency: Optional[str] = None) -> Optional[Dict]:
        """ä½¿ç”¨é»˜è®¤æ—¥æœŸèŒƒå›´è·å–æ•°æ®çš„åŒæ­¥åŒ…è£…å™¨"""
        return asyncio.run(self.get_conversions_default_range_async(currency))
    
    def save_to_json(self, data: Dict, filename: Optional[str] = None) -> Optional[str]:
        """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
        if not data:
            print_step("ä¿å­˜å¤±è´¥", "æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return None
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        config.ensure_output_dirs()
        
        if not filename:
            filename = config.get_json_filename()
        
        filepath = os.path.join(config.OUTPUT_DIR, filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            print_step("JSONä¿å­˜æˆåŠŸ", f"æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
            return filepath
            
        except Exception as e:
            print_step("JSONä¿å­˜å¤±è´¥", f"ä¿å­˜å¤±è´¥: {str(e)}")
            return None
    
    def get_skipped_pages_summary(self) -> str:
        """è·å–è·³è¿‡é¡µé¢çš„æ‘˜è¦ä¿¡æ¯"""
        if not self.skipped_pages:
            return "æ²¡æœ‰è·³è¿‡ä»»ä½•é¡µé¢"
        
        return f"è·³è¿‡äº† {len(self.skipped_pages)} ä¸ªé¡µé¢: {self.skipped_pages}"
    
    def print_final_summary(self):
        """æ‰“å°æœ€ç»ˆæ‘˜è¦æŠ¥å‘Š"""
        print(f"\n{'='*60}")
        print("ğŸ“‹ å¼‚æ­¥APIæ•°æ®è·å–æ‘˜è¦æŠ¥å‘Š")
        print(f"{'='*60}")
        
        # è¿è¡Œæ—¶é—´
        runtime = self.resource_monitor.get_runtime_info()
        print(f"â±ï¸  æ€»è¿è¡Œæ—¶é—´: {runtime['runtime_formatted']}")
        
        # å¼‚æ­¥é…ç½®ä¿¡æ¯
        print(f"ğŸš€ å¼‚æ­¥é…ç½®: æœ€å¤§å¹¶å‘è¯·æ±‚æ•° {self.max_concurrent_requests}")
        
        # è·³è¿‡é¡µé¢ä¿¡æ¯
        if self.skipped_pages:
            print(f"âš ï¸  è·³è¿‡é¡µé¢: {len(self.skipped_pages)} ä¸ªé¡µé¢ - {self.skipped_pages}")
        else:
            print("âœ… è·³è¿‡é¡µé¢: æ— ")
        
        # æœ€ç»ˆèµ„æºçŠ¶æ€
        self.resource_monitor.print_resource_status("æœ€ç»ˆçŠ¶æ€", show_details=True)
        
        print(f"{'='*60}\n")

# ä¾¿æ·å‡½æ•°ï¼Œç”¨äºå‘åå…¼å®¹
def get_conversions_async(start_date: str, end_date: str, 
                         api_secret: Optional[str] = None, api_key: Optional[str] = None,
                         currency: Optional[str] = None, api_name: Optional[str] = None) -> Optional[Dict]:
    """
    ä¾¿æ·çš„å¼‚æ­¥conversionæ•°æ®è·å–å‡½æ•°
    
    Args:
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        api_secret: API Secretï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼
        api_key: API Keyï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼
        currency: è´§å¸ç±»å‹ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼
        api_name: APIåç§°ï¼Œç”¨äºæ—¥å¿—æ ‡è¯†
    
    Returns:
        dict: conversionæ•°æ®ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    api = AsyncInvolveAsiaAPI(api_secret, api_key)
    
    # å¼‚æ­¥è®¤è¯å’Œè·å–æ•°æ®
    async def fetch_data():
        if await api.authenticate():
            return await api.get_conversions_async(start_date, end_date, currency, api_name)
        return None
    
    return asyncio.run(fetch_data())

# æ€§èƒ½æµ‹è¯•å‡½æ•°
def compare_sync_vs_async_performance(start_date: str, end_date: str, 
                                    test_pages: int = 5) -> Dict[str, Any]:
    """
    æ¯”è¾ƒåŒæ­¥vså¼‚æ­¥æ€§èƒ½
    
    Args:
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        test_pages: æµ‹è¯•é¡µæ•°
    
    Returns:
        dict: æ€§èƒ½æ¯”è¾ƒç»“æœ
    """
    print_step("æ€§èƒ½æµ‹è¯•", f"å¼€å§‹æ¯”è¾ƒåŒæ­¥vså¼‚æ­¥æ€§èƒ½ (æµ‹è¯•{test_pages}é¡µ)")
    
    # é™åˆ¶æµ‹è¯•èŒƒå›´é¿å…è¿‡å¤šAPIè°ƒç”¨
    original_limit = getattr(config, 'MAX_RECORDS_LIMIT', None)
    config.MAX_RECORDS_LIMIT = test_pages * config.DEFAULT_PAGE_LIMIT
    
    try:
        # æµ‹è¯•å¼‚æ­¥ç‰ˆæœ¬
        print_step("å¼‚æ­¥æµ‹è¯•", "æµ‹è¯•å¼‚æ­¥APIæ€§èƒ½...")
        async_start = time.time()
        async_api = AsyncInvolveAsiaAPI()
        
        async def test_async():
            if await async_api.authenticate():
                return await async_api.get_conversions_async(start_date, end_date)
            return None
        
        async_result = asyncio.run(test_async())
        async_time = time.time() - async_start
        
        # æµ‹è¯•åŒæ­¥ç‰ˆæœ¬ï¼ˆå¯¼å…¥åŸå§‹æ¨¡å—ï¼‰
        print_step("åŒæ­¥æµ‹è¯•", "æµ‹è¯•åŒæ­¥APIæ€§èƒ½...")
        from modules.involve_asia_api import InvolveAsiaAPI
        
        sync_start = time.time()
        sync_api = InvolveAsiaAPI()
        sync_result = None
        
        if sync_api.authenticate():
            sync_result = sync_api.get_conversions(start_date, end_date)
        
        sync_time = time.time() - sync_start
        
        # è®¡ç®—æ€§èƒ½æå‡
        performance_ratio = sync_time / async_time if async_time > 0 else 0
        time_saved = sync_time - async_time
        
        result = {
            "async_time": async_time,
            "sync_time": sync_time,
            "performance_ratio": performance_ratio,
            "time_saved_seconds": time_saved,
            "async_records": len(async_result.get("data", {}).get("data", [])) if async_result else 0,
            "sync_records": len(sync_result.get("data", {}).get("data", [])) if sync_result else 0,
            "async_success": async_result is not None,
            "sync_success": sync_result is not None
        }
        
        print_step("æ€§èƒ½æµ‹è¯•ç»“æœ", 
                  f"å¼‚æ­¥: {async_time:.2f}s, åŒæ­¥: {sync_time:.2f}s, "
                  f"æ€§èƒ½æå‡: {performance_ratio:.2f}x, èŠ‚çœæ—¶é—´: {time_saved:.2f}s")
        
        return result
        
    finally:
        # æ¢å¤åŸå§‹è®¾ç½®
        config.MAX_RECORDS_LIMIT = original_limit

# å¯¼å‡ºä¸»è¦ç±»å’Œå‡½æ•°
__all__ = [
    'AsyncInvolveAsiaAPI',
    'get_conversions_async', 
    'compare_sync_vs_async_performance'
] 