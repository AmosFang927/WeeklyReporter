#!/usr/bin/env python3
"""
Enhanced ByteC Network Dashboard
åƒè€ƒ Involve Asia å°ˆæ¥­è¨­è¨ˆçš„æ•¸æ“šåˆ†æå¹³å°
æ”¯æŒ AI æŸ¥è©¢ã€åœ–è¡¨è¦–è¦ºåŒ–å’Œè©³ç´°æ•¸æ“šå ±è¡¨
"""

import os
import asyncio
import asyncpg
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.utils import PlotlyJSONEncoder
import json
from decimal import Decimal
from datetime import datetime, timedelta
import streamlit as st
from typing import List, Dict, Optional, Tuple
import logging
import threading
from concurrent.futures import ThreadPoolExecutor
import socket
import time
import google.generativeai as genai
import re

# PandasAI ç›¸å…³å¯¼å…¥
try:
    from pandasai import SmartDataframe
    from pandasai.llm import GoogleGemini
    PANDASAI_AVAILABLE = True
except ImportError:
    PANDASAI_AVAILABLE = False
    print("PandasAI not available. AI query functionality will be disabled.")

# ç”Ÿäº§ç¯å¢ƒé…ç½®
ENVIRONMENT = os.getenv("ENVIRONMENT", "development")
IS_PRODUCTION = ENVIRONMENT == "production"

# è®¾ç½®æ—¥å¿—
log_level = logging.INFO if IS_PRODUCTION else logging.DEBUG
logging.basicConfig(
    level=log_level,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æ•°æ®åº“é…ç½®
POSTBACK_DB_CONFIG = {
    "host": os.getenv("DB_HOST", "34.124.206.16"),
    "port": int(os.getenv("DB_PORT", "5432")),
    "database": os.getenv("DB_NAME", "postback_db"),
    "user": os.getenv("DB_USER", "postback_admin"),
    "password": os.getenv("DB_PASSWORD", "ByteC2024PostBack_CloudSQL_20250708")
}

# Google Gemini APIé…ç½®
GEMINI_API_KEY = os.getenv("GOOGLE_GEMINI_API_KEY", "")

# è‡ªå®šä¹‰CSSæ ·å¼ - Involve Asia é£æ ¼
CUSTOM_CSS = """
<style>
    /* å…¨å±€æ ·å¼ */
    .main > div {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    
    /* æ ‡é¢˜æ ·å¼ */
    .main-title {
        font-size: 2.5rem;
        font-weight: 700;
        color: #2c3e50;
        margin-bottom: 0.5rem;
    }
    
    .sub-title {
        font-size: 1.1rem;
        color: #7f8c8d;
        margin-bottom: 2rem;
    }
    
    /* å…³é”®æŒ‡æ ‡å¡ç‰‡æ ·å¼ */
    .metric-card {
        background: white;
        border-radius: 8px;
        padding: 1.5rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #3498db;
        margin-bottom: 1rem;
    }
    
    .metric-value {
        font-size: 2.5rem;
        font-weight: 700;
        color: #2c3e50;
        margin-bottom: 0.5rem;
    }
    
    .metric-label {
        font-size: 0.9rem;
        color: #7f8c8d;
        text-transform: uppercase;
        font-weight: 500;
    }
    
    /* ç­›é€‰å™¨æ ·å¼ */
    .filter-section {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 8px;
        margin-bottom: 2rem;
    }
    
    .filter-title {
        font-size: 1.2rem;
        font-weight: 600;
        color: #2c3e50;
        margin-bottom: 1rem;
    }
    
    /* è¡¨æ ¼æ ·å¼ */
    .dataframe {
        font-size: 0.9rem;
    }
    
    .dataframe th {
        background-color: #f8f9fa;
        color: #2c3e50;
        font-weight: 600;
    }
    
    .dataframe td {
        padding: 0.75rem;
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background-color: #3498db;
        color: white;
        border: none;
        border-radius: 4px;
        padding: 0.5rem 1rem;
        font-weight: 500;
    }
    
    .stButton > button:hover {
        background-color: #2980b9;
    }
    
    /* AIæŸ¥è¯¢åŒºåŸŸæ ·å¼ */
    .ai-query-section {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 12px;
        margin-bottom: 2rem;
        color: white;
    }
    
    .ai-query-title {
        font-size: 1.3rem;
        font-weight: 600;
        margin-bottom: 1rem;
    }
    
    /* åœ–è¡¨å®¹å™¨ */
    .chart-container {
        background: white;
        border-radius: 8px;
        padding: 1.5rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin-bottom: 2rem;
    }
    
    /* éš±è—Streamlité»˜èªå…ƒç´  */
    .stDeployButton {
        display: none;
    }
    
    footer {
        display: none;
    }
    
    .stMainBlockContainer {
        padding-top: 1rem;
    }
    
    /* Company Summary ç‰¹æ®Šæ ·å¼ */
    .negative-roi {
        color: #e74c3c !important;
        font-weight: bold;
    }
    
    .positive-roi {
        color: #27ae60 !important;
        font-weight: bold;
    }
    
    /* å¯æŠ˜å å€åŸŸæ¨£å¼ */
    .streamlit-expanderHeader {
        background-color: #f8f9fa;
        border-radius: 8px;
        border: 1px solid #dee2e6;
    }
    
    .streamlit-expanderContent {
        background-color: #ffffff;
        border: 1px solid #dee2e6;
        border-top: none;
        border-radius: 0 0 8px 8px;
        padding: 1rem;
    }
    
    /* åˆ†éš”ç·šæ¨£å¼ */
    .section-divider {
        border: none;
        height: 2px;
        background: linear-gradient(to right, #e3f2fd, #1976d2, #e3f2fd);
        margin: 2.5rem 0;
        border-radius: 1px;
    }
    
    .section-divider-thin {
        border: none;
        height: 1px;
        background: linear-gradient(to right, transparent, #d1d5db, transparent);
        margin: 1.5rem 0;
    }
    
    .section-divider-space {
        height: 2rem;
        background: transparent;
        margin: 1rem 0;
    }
</style>
"""

# æ·»åŠ  Partner æ˜ å°„é…ç½®å’Œå‡½æ•¸
PARTNER_SOURCES_MAPPING = {
    "RAMPUP": {
        "sources": ["RAMPUP"],
        "pattern": r"^(RAMPUP|RPID.*)",
    },
    "YueMeng": {
        "sources": ["OPPO", "VIVO", "OEM2", "OEM3"],
        "pattern": r"^(OPPO|VIVO|OEM2|OEM3).*",
    },
    "TestPartner": {
        "sources": ["TestPartner"],
        "pattern": r"^TestPartner.*",
    },
    "MKK": {
        "sources": ["MKK"],
        "pattern": r"^MKK.*",
    },
    "ByteC": {
        "sources": ["ALL"],
        "pattern": r".*",
    }
}

# ä½£é‡‘ç‡é…ç½® (ByteC æŠ¥è¡¨ä¸“ç”¨)
# å¹¿å‘Šä¸»ä½£é‡‘ç‡é…ç½® (Adv Commission Rate)
ADV_COMMISSION_RATE_MAPPING = {
    "LisaidByteC": "dynamic",  # ä½¿ç”¨Avg. Commission Rateå­—æ®µå€¼
    "IAByteC": "dynamic"  # ä½¿ç”¨Avg. Commission Rateå­—æ®µå€¼
}

# å‘å¸ƒå•†ä½£é‡‘ç‡é…ç½® (Pub Commission Rate) 
PUB_COMMISSION_RATE_MAPPING = {
    # RAMPUP Partneré…ç½®
    ("RAMPUP", "Shopee ID (Media Buyers) - CPS"): 2.5,
    ("RAMPUP", "Shopee PH - CPS"): 2.7,
    
    # YueMeng Partneré…ç½®
    ("YueMeng", "TikTok Shop ID - CPS"): 1.0,
    ("YueMeng", "Shopee TH - CPS"): 2.0,
    ("YueMeng", "Shopee MY - CPS"): 2.0,
    ("YueMeng", "Shopee PH - CPS"): 2.5,
    ("YueMeng", "Shopee ID (Media Buyers) - CPS"): 1.5,
    ("YueMeng", "Shopee VN - CPS"): 3.0,
    
    # ByteC Partneré…ç½®
    ("ByteC", "Shopee ID (Media Buyers) - CPS"): 1.0,
    
    # MKK Partneré…ç½®
    ("MKK", "Shopee ID (Media Buyers) - CPS"): 1.0,
    ("MKK", "Shopee PH - CPS"): 1.0,
    ("MKK", "Shopee TH - CPS"): 1.0,
    ("MKK", "Shopee MY - CPS"): 1.0,
    ("MKK", "Shopee VN - CPS"): 1.0,
    ("MKK", "TikTok Shop ID - CPS"): 1.0,
}

# é»˜è®¤å‘å¸ƒå•†ä½£é‡‘ç‡
DEFAULT_PUB_COMMISSION_RATE = 1.0  # 1%

def match_source_to_partner(source_name):
    """å°‡ Source æ˜ å°„åˆ°å°æ‡‰çš„ Partner"""
    if not source_name:
        return "Unknown"
    
    for partner, config in PARTNER_SOURCES_MAPPING.items():
        if partner == "ByteC":  # è·³é ByteC é…ç½®
            continue
            
        # å…ˆæª¢æŸ¥ sources åˆ—è¡¨
        if source_name in config.get('sources', []):
            return partner
        
        # å†æª¢æŸ¥æ­£å‰‡è¡¨é”å¼æ¨¡å¼
        pattern = config.get('pattern', '')
        if pattern and re.match(pattern, source_name):
            return partner
    
    # å¦‚æœæ²’æœ‰åŒ¹é…åˆ°ï¼Œè¿”å›åŸå§‹ source_name ä½œç‚º partner
    return source_name

def get_adv_commission_rate(platform_name, avg_commission_rate=None):
    """
    è·å–å¹¿å‘Šä¸»ä½£é‡‘ç‡ (Adv Commission Rate)
    
    Args:
        platform_name: å¹³å°åç§° (LisaidByteC, IAByteCç­‰)
        avg_commission_rate: å½“å‰è®°å½•çš„å¹³å‡ä½£é‡‘ç‡ (ç™¾åˆ†æ¯”æ ¼å¼)
    
    Returns:
        float: å¹¿å‘Šä¸»ä½£é‡‘ç‡ (ç™¾åˆ†æ¯”)
    """
    if platform_name in ADV_COMMISSION_RATE_MAPPING:
        rate_config = ADV_COMMISSION_RATE_MAPPING[platform_name]
        if rate_config == "dynamic":
            # ä½¿ç”¨åŠ¨æ€å€¼(Avg. Commission Rate)
            return avg_commission_rate if avg_commission_rate is not None else 0.0
        else:
            # ä½¿ç”¨å›ºå®šå€¼
            return float(rate_config)
    else:
        # æœªé…ç½®çš„å¹³å°ä½¿ç”¨é»˜è®¤å€¼0%
        return 0.0

def get_pub_commission_rate(partner_name, offer_name):
    """
    è·å–å‘å¸ƒå•†ä½£é‡‘ç‡ (Pub Commission Rate)
    
    Args:
        partner_name: Partneråç§°
        offer_name: Offeråç§°
    
    Returns:
        float: å‘å¸ƒå•†ä½£é‡‘ç‡ (ç™¾åˆ†æ¯”)
    """
    mapping_key = (partner_name, offer_name)
    if mapping_key in PUB_COMMISSION_RATE_MAPPING:
        return float(PUB_COMMISSION_RATE_MAPPING[mapping_key])
    else:
        # æœªé…ç½®çš„ç»„åˆä½¿ç”¨é»˜è®¤å€¼
        return float(DEFAULT_PUB_COMMISSION_RATE)

# å°å…¥åŸæœ‰çš„é¡ï¼ˆé€™äº›é¡å·²ç¶“å­˜åœ¨æ–¼ pandasai_web_app.py ä¸­ï¼‰
if PANDASAI_AVAILABLE:
    class FixedGoogleGemini(GoogleGemini):
        def __init__(self, api_key: str, model: str = "gemini-1.5-flash"):
            super().__init__(api_key=api_key, model=model)
            self.model_name = model
            
        def generate_response(self, prompt: str) -> str:
            try:
                import google.generativeai as genai
                genai.configure(api_key=self.api_key)
                model = genai.GenerativeModel(self.model_name)
                response = model.generate_content(prompt)
                return response.text if response else "æŠ±æ­‰ï¼Œç„¡æ³•ç”Ÿæˆå›æ‡‰ã€‚"
            except Exception as e:
                return f"ç”Ÿæˆå›æ‡‰æ™‚å‡ºéŒ¯ï¼š{str(e)}"

class PandasAIManager:
    """PandasAIç®¡ç†å™¨"""
    
    def __init__(self):
        self.llm = None
        self.smart_dfs = {}
        self.initialize_llm()
    
    def initialize_llm(self):
        """åˆå§‹åŒ–LLM"""
        if not PANDASAI_AVAILABLE:
            return
        
        if not GEMINI_API_KEY:
            return
        
        try:
            self.llm = FixedGoogleGemini(
                api_key=GEMINI_API_KEY,
                model="models/gemini-2.5-flash"
            )
            logger.info("âœ… Google Gemini LLM åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ LLM åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def create_smart_dataframe(self, df: pd.DataFrame, name: str) -> Optional['SmartDataframe']:
        """åˆ›å»ºæ™ºèƒ½æ•°æ®æ¡†"""
        if not PANDASAI_AVAILABLE or not self.llm or df is None or df.empty:
            return None
        
        try:
            smart_df = SmartDataframe(df, config={
                "llm": self.llm,
                "verbose": True,
                "conversational": True,
                "save_charts": True,
                "save_charts_path": "charts/",
                "cache_path": f"cache/{name}_cache.db"
            })
            self.smart_dfs[name] = smart_df
            logger.info(f"âœ… åˆ›å»ºæ™ºèƒ½æ•°æ®æ¡† '{name}' æˆåŠŸ")
            return smart_df
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ™ºèƒ½æ•°æ®æ¡†å¤±è´¥: {e}")
            return None
    
    def query_dataframe(self, query: str, df_name: str = "main") -> tuple:
        """æŸ¥è¯¢æ•°æ®æ¡†"""
        if not PANDASAI_AVAILABLE or not self.llm:
            return None, "PandasAI ä¸å¯ç”¨"
        
        if df_name not in self.smart_dfs:
            return None, f"æ•°æ®æ¡† '{df_name}' ä¸å­˜åœ¨"
        
        try:
            smart_df = self.smart_dfs[df_name]
            result = smart_df.chat(query)
            return result, None
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
            return None, str(e)

class PostbackDataManager:
    """æ•¸æ“šç®¡ç†å™¨"""
    
    def __init__(self):
        self._cache = {}
        self._cache_timestamp = {}
        self._cache_duration = 300  # 5åˆ†é’Ÿç¼“å­˜
        self._connection_pool = None
        self._executor = ThreadPoolExecutor(max_workers=4)
    
    def _run_async(self, coro):
        """é‹è¡Œç•°æ­¥å”ç¨‹"""
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # å¦‚æœäº‹ä»¶å¾ªç’°å·²åœ¨é‹è¡Œï¼Œå‰µå»ºæ–°ä»»å‹™
                import nest_asyncio
                nest_asyncio.apply()
                return loop.run_until_complete(coro)
            else:
                return loop.run_until_complete(coro)
        except RuntimeError:
            # å¦‚æœæ²’æœ‰äº‹ä»¶å¾ªç’°ï¼Œå‰µå»ºæ–°çš„
            return asyncio.run(coro)
    
    async def _get_db_connection(self):
        """ç²å–æ•¸æ“šåº«é€£æ¥"""
        try:
            conn_string = f"postgresql://{POSTBACK_DB_CONFIG['user']}:{POSTBACK_DB_CONFIG['password']}@{POSTBACK_DB_CONFIG['host']}:{POSTBACK_DB_CONFIG['port']}/{POSTBACK_DB_CONFIG['database']}"
            conn = await asyncpg.connect(conn_string, command_timeout=30)
            return conn
        except Exception as e:
            logger.error(f"æ•¸æ“šåº«é€£æ¥å¤±æ•—: {e}")
            raise
    
    def _is_cache_valid(self, key: str) -> bool:
        """æª¢æŸ¥ç·©å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if key not in self._cache_timestamp:
            return False
        return (time.time() - self._cache_timestamp[key]) < self._cache_duration
    
    def _convert_decimal_to_float(self, data: List[Dict]) -> List[Dict]:
        """è½‰æ› Decimal åˆ° float"""
        for row in data:
            for key, value in row.items():
                if isinstance(value, Decimal):
                    row[key] = float(value)
        return data
    
    def get_partners(self) -> Dict[str, Dict]:
        """ç²å– Partners åˆ—è¡¨"""
        cache_key = "partners"
        if self._is_cache_valid(cache_key):
            return self._cache[cache_key]
        
        result = self._run_async(self._get_partners())
        self._cache[cache_key] = result
        self._cache_timestamp[cache_key] = time.time()
        return result
    
    # ä¿®æ”¹ Partners æŸ¥è©¢ä»¥ä½¿ç”¨æ­£ç¢ºçš„ partners è¡¨
    async def _get_partners(self) -> Dict[str, Dict]:
        """ç•°æ­¥ç²å– Platformsï¼ˆåŸæœ¬çš„ Partnersï¼‰"""
        conn = await self._get_db_connection()
        try:
            # é¦–å…ˆå˜—è©¦å¾ partners è¡¨ç²å–
            query = """
                SELECT DISTINCT 
                    p.id as platform_id,
                    p.partner_name as platform_name,
                    p.partner_code as platform_code
                FROM partners p
                WHERE p.is_active = true
                ORDER BY p.partner_name
            """
            
            rows = await conn.fetch(query)
            platforms = {}
            
            if rows:
                # å¦‚æœ partners è¡¨æœ‰æ•¸æ“šï¼Œä½¿ç”¨ partners è¡¨
                for row in rows:
                    platform_id = row['platform_id']
                    platforms[str(platform_id)] = {
                        'id': platform_id,
                        'name': row['platform_name'],
                        'code': row['platform_code']
                    }
                logger.info(f"âœ… å¾ partners è¡¨ç²å– {len(platforms)} å€‹ Platform")
            else:
                # å¦‚æœæ²’æœ‰ partners è¡¨æˆ–æ•¸æ“šï¼Œå¾ tenants è¡¨ç²å–
                query = """
                    SELECT DISTINCT 
                        t.id as platform_id,
                        t.tenant_name as platform_name,
                        t.tenant_code as platform_code
                    FROM tenants t
                    WHERE t.is_active = true
                    ORDER BY t.tenant_name
                """
                
                rows = await conn.fetch(query)
                for row in rows:
                    platform_id = row['platform_id']
                    platforms[str(platform_id)] = {
                        'id': platform_id,
                        'name': row['platform_name'],
                        'code': row['platform_code']
                    }
                logger.info(f"âœ… å¾ tenants è¡¨ç²å– {len(platforms)} å€‹ Platform")
            
            return platforms
            
        except Exception as e:
            logger.error(f"âŒ ç²å– Platform å¤±æ•—: {str(e)}")
            return {}
        finally:
            await conn.close()

    def get_comprehensive_data(self, days: int = 7, partner_id: Optional[int] = None) -> pd.DataFrame:
        """ç²å–ç¶œåˆæ•¸æ“š"""
        cache_key = f"comprehensive_{days}_{partner_id}"
        if self._is_cache_valid(cache_key):
            return self._cache[cache_key]
        
        result = self._run_async(self._get_comprehensive_data(days, partner_id))
        self._cache[cache_key] = result
        self._cache_timestamp[cache_key] = time.time()
        return result
    
    # ä¿®æ”¹ç¶œåˆæ•¸æ“šæŸ¥è©¢ï¼Œéæ¿¾æ¸¬è©¦æ•¸æ“šä¸¦æ·»åŠ  Partner æ¬„ä½
    async def _get_comprehensive_data(self, days: int = 7, partner_id: Optional[int] = None) -> pd.DataFrame:
        """ç•°æ­¥ç²å–ç¶œåˆæ•¸æ“š"""
        conn = await self._get_db_connection()
        try:
            # æ§‹å»ºæŸ¥è©¢æ¢ä»¶
            where_clause = f"WHERE DATE(c.created_at) >= CURRENT_DATE - INTERVAL '{days} days'"
            
            # æ·»åŠ æ¸¬è©¦æ•¸æ“šéæ¿¾æ¢ä»¶ - æ›´æ™ºèƒ½çš„è¿‡æ»¤ï¼Œåªè¿‡æ»¤æ˜æ˜¾çš„æµ‹è¯•æ•°æ®
            where_clause += """
                AND c.conversion_id NOT ILIKE 'test_%'
                AND c.conversion_id NOT ILIKE 'TEST_%'
                AND c.conversion_id NOT ILIKE '%_test'
                AND c.conversion_id NOT ILIKE '%_TEST'
                AND c.conversion_id NOT ILIKE '{conversion_id}'
                AND c.conversion_id NOT ILIKE '{offer_name}'
                AND c.conversion_id != ''
                AND c.conversion_id IS NOT NULL
                AND COALESCE(c.offer_name, '') NOT ILIKE 'test %'
                AND COALESCE(c.offer_name, '') NOT ILIKE 'TEST %'
                AND COALESCE(c.offer_name, '') NOT ILIKE '% test'
                AND COALESCE(c.offer_name, '') NOT ILIKE '% TEST'
            """
            
            if partner_id and partner_id != 1:  # å¦‚æœä¸æ˜¯é»˜èª partner
                where_clause += f" AND c.partner_id = {partner_id}"
            
            # æŸ¥è©¢æ•¸æ“šï¼Œåªä½¿ç”¨å¯¦éš›å­˜åœ¨çš„å­—æ®µ
            query = f"""
                SELECT 
                    DATE(c.created_at) as date,
                    c.partner_id as platform_id,
                    COALESCE(p.partner_name, t.tenant_name, 'Unknown Platform') as platform_name,
                    COALESCE(p.partner_code, t.tenant_code, 'unknown') as platform_code,
                    COALESCE(c.offer_name, 'Unknown Offer') as offer_name,
                    COALESCE(c.aff_sub, c.conversion_id) as aff_sub,
                    COALESCE(c.aff_sub, c.conversion_id) as sub_id,
                    COALESCE(c.usd_sale_amount, 0) as conversion_value,
                    COALESCE(c.usd_payout, 0) as payout,
                    c.conversion_id,
                    c.partner_id,
                    c.event_time,
                    c.created_at,
                    c.raw_data,
                    -- è®¡ç®— avg_commission_rate å­—æ®µ
                    CASE 
                        WHEN COALESCE(c.usd_sale_amount, 0) > 0 THEN 
                            (COALESCE(c.usd_payout, 0) / COALESCE(c.usd_sale_amount, 0)) * 100
                        ELSE 0 
                    END as avg_commission_rate
                FROM conversions c
                LEFT JOIN tenants t ON c.tenant_id = t.id
                LEFT JOIN partners p ON c.partner_id = p.id
                {where_clause}
                ORDER BY c.created_at DESC
            """
            
            result = await conn.fetch(query)
            data = self._convert_decimal_to_float([dict(row) for row in result])
            
            # è½‰æ›ç‚º DataFrame
            df = pd.DataFrame(data)
            
            # æ·»åŠ  Partner æ¬„ä½ï¼ˆå¾ aff_sub è§£æï¼‰
            if not df.empty:
                df['partner_name'] = df['aff_sub'].apply(match_source_to_partner)
                
                # ä¿®å¾©æ—¥æœŸæ ¼å¼å•é¡Œ
                if 'date' in df.columns:
                    df['date'] = pd.to_datetime(df['date']).dt.date
                if 'event_time' in df.columns:
                    df['event_time'] = pd.to_datetime(df['event_time'])
                if 'created_at' in df.columns:
                    df['created_at'] = pd.to_datetime(df['created_at'])
                
            self._cache[f"comprehensive_data_{days}_{partner_id}"] = df
            self._cache_timestamp[f"comprehensive_data_{days}_{partner_id}"] = datetime.now()
            
            logger.info(f"âœ… ç²å–ç¶œåˆæ•¸æ“šæˆåŠŸ: {len(df)} æ¢è¨˜éŒ„")
            return df
            
        except Exception as e:
            logger.error(f"âŒ ç²å–ç¶œåˆæ•¸æ“šå¤±æ•—: {str(e)}")
            return pd.DataFrame()
        finally:
            await conn.close()
    
    def get_performance_metrics(self, days: int = 7, partner_id: Optional[int] = None) -> Dict:
        """ç²å–æ€§èƒ½æŒ‡æ¨™"""
        cache_key = f"metrics_{days}_{partner_id}"
        if self._is_cache_valid(cache_key):
            return self._cache[cache_key]
        
        result = self._run_async(self._get_performance_metrics_async(days, partner_id))
        self._cache[cache_key] = result
        self._cache_timestamp[cache_key] = time.time()
        return result
    
    # ä¿®æ”¹æ€§èƒ½æŒ‡æ¨™æŸ¥è©¢ï¼Œéæ¿¾æ¸¬è©¦æ•¸æ“š
    async def _get_performance_metrics_async(self, days: int = 7, partner_id: Optional[int] = None) -> Dict:
        """ç•°æ­¥ç²å–æ€§èƒ½æŒ‡æ¨™"""
        conn = await self._get_db_connection()
        try:
            where_clause = f"WHERE DATE(c.created_at) >= CURRENT_DATE - INTERVAL '{days} days'"
            
            # æ·»åŠ æ¸¬è©¦æ•¸æ“šéæ¿¾æ¢ä»¶ - æ›´æ™ºèƒ½çš„è¿‡æ»¤ï¼Œåªè¿‡æ»¤æ˜æ˜¾çš„æµ‹è¯•æ•°æ®
            where_clause += """
                AND c.conversion_id NOT ILIKE 'test_%'
                AND c.conversion_id NOT ILIKE 'TEST_%'
                AND c.conversion_id NOT ILIKE '%_test'
                AND c.conversion_id NOT ILIKE '%_TEST'
                AND c.conversion_id NOT ILIKE '{conversion_id}'
                AND c.conversion_id NOT ILIKE '{offer_name}'
                AND c.conversion_id != ''
                AND c.conversion_id IS NOT NULL
                AND COALESCE(c.offer_name, '') NOT ILIKE 'test %'
                AND COALESCE(c.offer_name, '') NOT ILIKE 'TEST %'
                AND COALESCE(c.offer_name, '') NOT ILIKE '% test'
                AND COALESCE(c.offer_name, '') NOT ILIKE '% TEST'
            """
            
            if partner_id and partner_id != 1:  # å¦‚æœä¸æ˜¯é»˜èª platform
                where_clause += f" AND c.partner_id = {partner_id}"
            
            query = f"""
                SELECT 
                    COUNT(*) as total_conversions,
                    SUM(COALESCE(c.usd_sale_amount, 0)) as total_sales,
                    SUM(COALESCE(c.usd_payout, 0)) as total_earnings,
                    COUNT(DISTINCT COALESCE(c.aff_sub, c.conversion_id)) as unique_clicks,
                    AVG(COALESCE(c.usd_sale_amount, 0)) as avg_order_value,
                    AVG(COALESCE(c.usd_payout, 0)) as avg_payout
                FROM conversions c
                {where_clause}
            """
            
            result = await conn.fetchrow(query)
            
            # è½‰æ› Decimal åˆ° float
            data = dict(result) if result else {}
            data = self._convert_decimal_to_float([data])[0] if data else {}
            
            # è¨ˆç®— CR (Conversion Rate) å’Œ Avg. Commission Rate
            total_clicks = data.get('unique_clicks', 0) or 0
            total_conversions = data.get('total_conversions', 0) or 0
            total_sales = data.get('total_sales', 0) or 0
            total_earnings = data.get('total_earnings', 0) or 0
            
            # CR = Conversions / Clicks
            cr = (total_conversions / total_clicks * 100) if total_clicks > 0 else 0
            
            # Avg. Commission Rate = Total Earnings / Total Sales
            avg_commission_rate = (total_earnings / total_sales * 100) if total_sales > 0 else 0
            
            metrics = {
                'total_clicks': total_clicks,
                'total_conversions': total_conversions,
                'total_sales': total_sales,
                'total_earnings': total_earnings,
                'avg_order_value': data.get('avg_order_value', 0),
                'avg_payout': data.get('avg_payout', 0),
                'cr': cr,
                'avg_commission_rate': avg_commission_rate
            }
            
            return metrics
            
        except Exception as e:
            logger.error(f"âŒ ç²å–æ€§èƒ½æŒ‡æ¨™å¤±æ•—: {str(e)}")
            return {
                'total_clicks': 0,
                'total_conversions': 0,
                'total_sales': 0,
                'total_earnings': 0,
                'avg_order_value': 0,
                'avg_payout': 0,
                'cr': 0,
                'avg_commission_rate': 0
            }
        finally:
            await conn.close()
    
    def get_offers_list(self, partner_id: Optional[int] = None) -> List[str]:
        """ç²å– Offers åˆ—è¡¨"""
        cache_key = f"offers_{partner_id}"
        if self._is_cache_valid(cache_key):
            return self._cache[cache_key]
        
        result = self._run_async(self._get_offers_list_async(partner_id))
        self._cache[cache_key] = result
        self._cache_timestamp[cache_key] = time.time()
        return result
    
    # ä¿®æ”¹ offers æŸ¥è©¢ï¼Œéæ¿¾æ¸¬è©¦æ•¸æ“š
    async def _get_offers_list_async(self, partner_id: Optional[int] = None) -> List[str]:
        """ç•°æ­¥ç²å– Offers åˆ—è¡¨"""
        conn = await self._get_db_connection()
        try:
            where_clause = """
                WHERE c.offer_name IS NOT NULL
                AND c.conversion_id NOT ILIKE 'test_%'
                AND c.conversion_id NOT ILIKE 'TEST_%'
                AND c.conversion_id NOT ILIKE '%_test'
                AND c.conversion_id NOT ILIKE '%_TEST'
                AND c.conversion_id NOT ILIKE '{conversion_id}'
                AND c.conversion_id NOT ILIKE '{offer_name}'
                AND c.conversion_id != ''
                AND c.conversion_id IS NOT NULL
                AND COALESCE(c.offer_name, '') NOT ILIKE 'test %'
                AND COALESCE(c.offer_name, '') NOT ILIKE 'TEST %'
                AND COALESCE(c.offer_name, '') NOT ILIKE '% test'
                AND COALESCE(c.offer_name, '') NOT ILIKE '% TEST'
            """
            
            if partner_id and partner_id != 1:  # å¦‚æœä¸æ˜¯é»˜èª partner
                where_clause += f" AND c.partner_id = {partner_id}"
            
            query = f"""
                SELECT DISTINCT c.offer_name
                FROM conversions c
                {where_clause}
                ORDER BY c.offer_name
            """
            
            rows = await conn.fetch(query)
            offers = [row['offer_name'] for row in rows if row['offer_name']]
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°ä»»ä½• offersï¼Œè¿”å›é»˜èªé¸é …
            if not offers:
                offers = ['No Offers Available']
            
            return offers
        finally:
            await conn.close()

def create_metric_card(title: str, value: str, icon: str = "ğŸ“Š") -> None:
    """å‰µå»ºæŒ‡æ¨™å¡ç‰‡"""
    st.markdown(f"""
        <div class="metric-card">
            <div class="metric-label">{icon} {title}</div>
            <div class="metric-value">{value}</div>
        </div>
    """, unsafe_allow_html=True)

# æ›´æ–°æ ¼å¼åŒ–å‡½æ•¸
def format_number(value: float, format_type: str = "number") -> str:
    """æ ¼å¼åŒ–æ•¸å­—"""
    if format_type == "currency":
        return f"${value:,.2f}"
    elif format_type == "percentage":
        return f"{value:.2f}%"
    elif format_type == "integer":
        return f"{value:,.0f}"
    else:
        return f"{value:,.0f}"

def create_section_divider(divider_type: str = "normal") -> None:
    """å‰µå»ºåˆ†éš”ç·š"""
    if divider_type == "major":
        st.markdown('<hr class="section-divider">', unsafe_allow_html=True)
    elif divider_type == "thin":
        st.markdown('<hr class="section-divider-thin">', unsafe_allow_html=True)
    elif divider_type == "space":
        st.markdown('<div class="section-divider-space"></div>', unsafe_allow_html=True)
    else:
        st.markdown('<hr class="section-divider">', unsafe_allow_html=True)

def create_performance_overview(metrics: Dict) -> None:
    """å‰µå»ºæ€§èƒ½æ¦‚è¦½å€åŸŸ"""
    st.markdown('<div class="filter-title">Performance Overview</div>', unsafe_allow_html=True)
    st.markdown('<p class="sub-title">View and filter your clicks, conversions, sales, and earnings.</p>', unsafe_allow_html=True)
    
    # å‰µå»º6å€‹æŒ‡æ¨™å¡ç‰‡
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ğŸ–±ï¸ Total Clicks",
            value=format_number(metrics['total_clicks'], "integer"),
            help="ç¸½é»æ“Šæ•¸"
        )
    
    with col2:
        st.metric(
            label="ğŸ¯ Total Conversions", 
            value=format_number(metrics['total_conversions'], "integer"),
            help="ç¸½è½‰åŒ–æ•¸"
        )
    
    with col3:
        st.metric(
            label="ğŸ’° Total Sales (USD)",
            value=format_number(metrics['total_sales'], "currency"),
            help="ç¸½éŠ·å”®é¡"
        )
    
    with col4:
        st.metric(
            label="ğŸ’¸ Total Earnings (USD)",
            value=format_number(metrics['total_earnings'], "currency"),
            help="ç¸½é ä¼°æ”¶ç›Š"
        )
    
    # ç¬¬äºŒè¡ŒæŒ‡æ¨™
    col5, col6 = st.columns(2)
    
    with col5:
        st.metric(
            label="ğŸ“ˆ CR (Conversion Rate)",
            value=format_number(metrics['cr'], "percentage"),
            help="è½‰åŒ–ç‡ = è½‰åŒ–æ•¸ / é»æ“Šæ•¸"
        )
    
    with col6:
        st.metric(
            label="ğŸ’ Avg. Commission Rate",
            value=format_number(metrics['avg_commission_rate'], "percentage"),
            help="å¹³å‡ä½£é‡‘ç‡ = ç¸½æ”¶ç›Š / ç¸½éŠ·å”®é¡"
        )

def create_company_level_summary(df: pd.DataFrame, start_date: datetime = None, end_date: datetime = None) -> None:
    """å‰µå»ºå…¬å¸ç´šåˆ¥æ±‡æ€» - åŒ…å«ç›ˆè™§è¨ˆç®—"""
    
    # å¯æŠ˜å ç•Œé¢
    with st.expander("ğŸ¢ Company Level Summary", expanded=True):
        if df.empty:
            st.warning("No data available for company summary.")
            return
        
        # ç‹¬ç«‹çš„æ—¥æœŸé€‰æ‹©å™¨
        col1, col2, col3 = st.columns([2, 2, 4])
        
        with col1:
            # é»˜è®¤æ—¥æœŸä¸ºä¼ å…¥çš„æ—¥æœŸèŒƒå›´æˆ–æœ€è¿‘7å¤©
            default_start = start_date if start_date else datetime.now() - timedelta(days=7)
            summary_start_date = st.date_input(
                "Summary Start Date", 
                value=default_start,
                key="company_summary_start"
            )
        
        with col2:
            default_end = end_date if end_date else datetime.now()
            summary_end_date = st.date_input(
                "Summary End Date", 
                value=default_end,
                key="company_summary_end"
            )
        
        # æŒ‰æ—¥æœŸè¿‡æ»¤æ•°æ®
        filtered_df = df.copy()
        if 'date' in filtered_df.columns:
            # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
            if filtered_df['date'].dtype == 'object':
                filtered_df['date'] = pd.to_datetime(filtered_df['date']).dt.date
            filtered_df = filtered_df[
                (filtered_df['date'] >= summary_start_date) & 
                (filtered_df['date'] <= summary_end_date)
            ]
        
        if filtered_df.empty:
            st.warning("No data found for the selected date range.")
            return
        
        # åŸºæœ¬ç»Ÿè®¡
        total_conversion = len(filtered_df)
        total_sales = filtered_df['conversion_value'].sum() if 'conversion_value' in filtered_df.columns else 0
        total_earning = filtered_df['payout'].sum() if 'payout' in filtered_df.columns else 0
        
        # ä½£é‡‘è®¡ç®—
        total_adv_commission = 0.0
        total_pub_commission = 0.0
        
        # æŒ‰è®°å½•è®¡ç®—ä½£é‡‘
        for _, row in filtered_df.iterrows():
            sales_amount = row.get('conversion_value', 0)
            avg_commission_rate = row.get('avg_commission_rate', 0)
            platform_name = row.get('platform_name', '')
            partner_name = row.get('partner_name', '')
            offer_name = row.get('offer_name', '')
            
            # è®¡ç®—å¹¿å‘Šä¸»ä½£é‡‘
            adv_rate = get_adv_commission_rate(platform_name, avg_commission_rate)
            adv_commission = sales_amount * (adv_rate / 100.0)
            total_adv_commission += adv_commission
            
            # è®¡ç®—å‘å¸ƒå•†ä½£é‡‘
            pub_rate = get_pub_commission_rate(partner_name, offer_name)
            pub_commission = sales_amount * (pub_rate / 100.0)
            total_pub_commission += pub_commission
        
        # ByteC ä½£é‡‘å’Œ ROI
        total_bytec_commission = total_adv_commission - total_pub_commission
        
        # ByteC ROI = (ByteC Commission / Estimated Earning) Ã— 100%
        bytec_roi = 0.0
        if total_earning > 0:
            bytec_roi = (total_bytec_commission / total_earning) * 100
        
        # åˆ›å»ºæ±‡æ€»è¡¨æ ¼æ•°æ®
        date_range_str = f"{summary_start_date} è‡³ {summary_end_date}"
        
        company_summary_data = {
            'Company': ['ByteC'],
            'Date Range': [date_range_str],
            'Conversions': [total_conversion],
            'Total Sales (USD)': [total_sales],
            'Total Earnings (USD)': [total_earning],
            'Total Adv Commission': [total_adv_commission],
            'Total Pub Commission': [total_pub_commission],
            'Total ByteC Commission': [total_bytec_commission],
            'ByteC ROI': [bytec_roi]
        }
        
        company_summary_df = pd.DataFrame(company_summary_data)
        
        # æ ¼å¼åŒ–æ•°æ® - ä¸ Partner Level Summary ä¿æŒä¸€è‡´
        company_summary_formatted = company_summary_df.copy()
        company_summary_formatted['Conversions'] = company_summary_formatted['Conversions'].apply(
            lambda x: format_number(x, "integer")
        )
        company_summary_formatted['Total Sales (USD)'] = company_summary_formatted['Total Sales (USD)'].apply(
            lambda x: format_number(x, "currency")
        )
        company_summary_formatted['Total Earnings (USD)'] = company_summary_formatted['Total Earnings (USD)'].apply(
            lambda x: format_number(x, "currency")
        )
        company_summary_formatted['Total Adv Commission'] = company_summary_formatted['Total Adv Commission'].apply(
            lambda x: format_number(x, "currency")
        )
        company_summary_formatted['Total Pub Commission'] = company_summary_formatted['Total Pub Commission'].apply(
            lambda x: format_number(x, "currency")
        )
        company_summary_formatted['Total ByteC Commission'] = company_summary_formatted['Total ByteC Commission'].apply(
            lambda x: format_number(x, "currency")
        )
        company_summary_formatted['ByteC ROI'] = company_summary_formatted['ByteC ROI'].apply(
            lambda x: f"{'ğŸ”´' if x < 0 else 'ğŸŸ¢'} {format_number(x, 'percentage')}"
        )
        
        # æ˜¾ç¤ºè¡¨æ ¼ - ä¸ Partner Level Summary ä¿æŒä¸€è‡´çš„é£æ ¼
        st.dataframe(company_summary_formatted, use_container_width=True)
        


def create_summary_tables(df: pd.DataFrame) -> None:
    """å‰µå»º ByteC é¢¨æ ¼çš„ç¸½è¡¨å€åŸŸ"""
    if df.empty:
        st.warning("No data available for summary tables.")
        return
    
    st.markdown('<div class="filter-title">ğŸ“Š Summary Tables</div>', unsafe_allow_html=True)
    st.markdown('<p class="sub-title">Comprehensive data breakdown by different dimensions.</p>', unsafe_allow_html=True)
    
    # 2. Partner Level Summary
    create_section_divider("thin")
    st.markdown("### ğŸ‘¥ Partner Level Summary")
    
    if 'partner_name' in df.columns and 'aff_sub' in df.columns:
        # åˆ›å»ºç»„åˆå­—æ®µï¼špartner_name + aff_sub
        df_with_combined = df.copy()
        df_with_combined['partner_source'] = df_with_combined['partner_name'] + '+' + df_with_combined['aff_sub'].astype(str)
        
        partner_summary = df_with_combined.groupby('partner_source').agg({
            'conversion_value': ['count', 'sum'],
            'payout': 'sum'
        }).round(2)
        
        # æ‰å¹³åŒ–åˆ—å
        partner_summary.columns = ['Conversions', 'Total Sales (USD)', 'Total Earnings (USD)']
        partner_summary['Avg. Commission Rate (%)'] = (
            partner_summary['Total Earnings (USD)'] / partner_summary['Total Sales (USD)'] * 100
        ).round(2)
        
        # æŒ‰ Total Sales éæ¸›æ’åºï¼ˆåœ¨æ ¼å¼åŒ–ä¹‹å‰ï¼‰
        partner_summary = partner_summary.sort_values('Total Sales (USD)', ascending=False)
        
        # æ ¼å¼åŒ–æ•¸æ“š
        partner_summary_formatted = partner_summary.copy()
        partner_summary_formatted['Conversions'] = partner_summary_formatted['Conversions'].apply(
            lambda x: format_number(x, "integer")
        )
        partner_summary_formatted['Total Sales (USD)'] = partner_summary_formatted['Total Sales (USD)'].apply(
            lambda x: format_number(x, "currency")
        )
        partner_summary_formatted['Total Earnings (USD)'] = partner_summary_formatted['Total Earnings (USD)'].apply(
            lambda x: format_number(x, "currency")
        )
        partner_summary_formatted['Avg. Commission Rate (%)'] = partner_summary_formatted['Avg. Commission Rate (%)'].apply(
            lambda x: format_number(x, "percentage")
        )
        
        # é‡ç½®ç´¢å¼•
        partner_summary_formatted = partner_summary_formatted.reset_index()
        
        st.dataframe(partner_summary_formatted, use_container_width=True)
    
    # 3. Offer Level Summary
    create_section_divider("thin")
    st.markdown("### ğŸ¯ Offer Level Summary")
    
    if 'offer_name' in df.columns:
        offer_summary = df.groupby('offer_name').agg({
            'conversion_value': ['count', 'sum'],
            'payout': 'sum'
        }).round(2)
        
        # æ‰å¹³åŒ–åˆ—å
        offer_summary.columns = ['Conversions', 'Total Sales (USD)', 'Total Earnings (USD)']
        offer_summary['Avg. Commission Rate (%)'] = (
            offer_summary['Total Earnings (USD)'] / offer_summary['Total Sales (USD)'] * 100
        ).round(2)
        
        # æŒ‰ Total Sales éæ¸›æ’åºï¼ˆåœ¨æ ¼å¼åŒ–ä¹‹å‰ï¼‰
        offer_summary = offer_summary.sort_values('Total Sales (USD)', ascending=False)
        
        # æ ¼å¼åŒ–æ•¸æ“š
        offer_summary_formatted = offer_summary.copy()
        offer_summary_formatted['Conversions'] = offer_summary_formatted['Conversions'].apply(
            lambda x: format_number(x, "integer")
        )
        offer_summary_formatted['Total Sales (USD)'] = offer_summary_formatted['Total Sales (USD)'].apply(
            lambda x: format_number(x, "currency")
        )
        offer_summary_formatted['Total Earnings (USD)'] = offer_summary_formatted['Total Earnings (USD)'].apply(
            lambda x: format_number(x, "currency")
        )
        offer_summary_formatted['Avg. Commission Rate (%)'] = offer_summary_formatted['Avg. Commission Rate (%)'].apply(
            lambda x: format_number(x, "percentage")
        )
        
        # é‡ç½®ç´¢å¼•
        offer_summary_formatted = offer_summary_formatted.reset_index()
        
        # é™åˆ¶é¡¯ç¤ºå‰10å€‹
        st.dataframe(offer_summary_formatted.head(10), use_container_width=True)
    
    st.markdown("---")

def create_detailed_report_table(df: pd.DataFrame) -> None:
    """å‰µå»ºè©³ç´°å ±å‘Šè¡¨æ ¼ - åƒè€ƒ InvolveAsia è¨­è¨ˆ"""
    if df.empty:
        st.warning("No data available for detailed report.")
        return
    
    st.markdown('<div class="filter-title">ğŸ“‹ Conversion Report</div>', unsafe_allow_html=True)
    
    # æ™‚é–“å‘¨æœŸé¸æ“‡å™¨å’Œå°å‡ºæŒ‰éˆ•
    col1, col2, col3, col4, col5, col6 = st.columns([1, 1, 1, 1, 1, 2])
    
    with col1:
        period_type = st.selectbox(
            "Period",
            options=["Day", "Week", "Month", "None"],
            index=0,  # é»˜èªé¸æ“‡ "Day"
            label_visibility="collapsed"
        )
    
    with col2:
        # æœç´¢æ¡†
        search_keyword = st.text_input(
            "Search",
            placeholder="Search by keyword...",
            label_visibility="collapsed"
        )
    
    with col6:
        # å°å‡ºæŒ‰éˆ•
        csv_data = df.to_csv(index=False)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        st.download_button(
            label="Export CSV",
            data=csv_data,
            file_name=f"bytec_report_{timestamp}.csv",
            mime="text/csv",
            type="secondary"
        )
    
    # è™•ç†æœç´¢åŠŸèƒ½
    filtered_df = df.copy()
    if search_keyword:
        mask = (
            filtered_df['offer_name'].str.contains(search_keyword, case=False, na=False) |
            filtered_df['platform_name'].str.contains(search_keyword, case=False, na=False) |
            filtered_df['partner_name'].str.contains(search_keyword, case=False, na=False)
        )
        filtered_df = filtered_df[mask]
    
    # ç¢ºä¿æ—¥æœŸæ ¼å¼æ­£ç¢º
    if 'date' in filtered_df.columns:
        # å¦‚æœæ˜¯dateç±»å‹ï¼Œè½¬æ¢ä¸ºdatetime
        if filtered_df['date'].dtype == 'object':
            filtered_df['date'] = pd.to_datetime(filtered_df['date'])
        elif str(filtered_df['date'].dtype) == 'date':
            filtered_df['date'] = pd.to_datetime(filtered_df['date'])
    
    # æ ¹æ“šæ™‚é–“å‘¨æœŸèšåˆæ•¸æ“š
    if period_type == "Day":
        # æŒ‰æ—¥æœŸå’Œ Offer èšåˆ
        grouped_df = filtered_df.groupby(['date', 'offer_name']).agg({
            'sub_id': 'nunique',  # é»æ“Šæ•¸ (å”¯ä¸€ Source æ•¸é‡)
            'conversion_value': ['count', 'sum'],  # è½‰åŒ–æ¬¡æ•¸å’ŒéŠ·å”®é¡
            'payout': 'sum',  # æ”¶ç›Š
            'platform_name': 'first',  # å¹³å°åç¨±
            'partner_name': 'first'  # åˆä½œå¤¥ä¼´åç¨±
        }).reset_index()
        
        # æ‰å¹³åŒ–åˆ—å
        grouped_df.columns = ['Date', 'Advertiser', 'Clicks', 'Conversions', 'Sale_Amount', 'Earnings', 'Platform', 'Partner']
        
    elif period_type == "Week":
        # æŒ‰é€±èšåˆ
        filtered_df['week'] = filtered_df['date'].dt.to_period('W')
        grouped_df = filtered_df.groupby(['week', 'offer_name']).agg({
            'sub_id': 'nunique',
            'conversion_value': ['count', 'sum'],
            'payout': 'sum',
            'platform_name': 'first',
            'partner_name': 'first'
        }).reset_index()
        grouped_df.columns = ['Date', 'Advertiser', 'Clicks', 'Conversions', 'Sale_Amount', 'Earnings', 'Platform', 'Partner']
        
    elif period_type == "Month":
        # æŒ‰æœˆèšåˆ
        filtered_df['month'] = filtered_df['date'].dt.to_period('M')
        grouped_df = filtered_df.groupby(['month', 'offer_name']).agg({
            'sub_id': 'nunique',
            'conversion_value': ['count', 'sum'],
            'payout': 'sum',
            'platform_name': 'first',
            'partner_name': 'first'
        }).reset_index()
        grouped_df.columns = ['Date', 'Advertiser', 'Clicks', 'Conversions', 'Sale_Amount', 'Earnings', 'Platform', 'Partner']
        
    else:  # None - é¡¯ç¤ºåŸå§‹æ•¸æ“š
        grouped_df = filtered_df.copy()
        grouped_df['Clicks'] = 1  # æ¯ç­†è¨˜éŒ„ç®—1æ¬¡é»æ“Š
        grouped_df['Conversions'] = 1  # æ¯ç­†è¨˜éŒ„ç®—1æ¬¡è½‰åŒ–
        grouped_df = grouped_df.rename(columns={
            'date': 'Date',
            'offer_name': 'Advertiser',
            'conversion_value': 'Sale_Amount',
            'payout': 'Earnings',
            'platform_name': 'Platform',
            'partner_name': 'Partner'
        })
    
    # è¨ˆç®—å¹³å‡ä½£é‡‘ç‡ (Avg. Commission Rate = Earnings / Sale Amount)
    grouped_df['Avg_Commission_Rate'] = (
        grouped_df['Earnings'] / grouped_df['Sale_Amount'] * 100
    ).fillna(0)
    
    # æ ¼å¼åŒ–æ•¸æ“š
    grouped_df['Conversions'] = grouped_df['Conversions'].apply(
        lambda x: f"{x:,}"
    )
    grouped_df['Sale Amount (USD)'] = grouped_df['Sale_Amount'].apply(
        lambda x: format_number(x, "currency")
    )
    grouped_df['Estimated Earnings (USD)'] = grouped_df['Earnings'].apply(
        lambda x: format_number(x, "currency")
    )
    grouped_df['Avg. Commission Rate (%)'] = grouped_df['Avg_Commission_Rate'].apply(
        lambda x: format_number(x, "percentage")
    )
    
    # æ ¼å¼åŒ–æ—¥æœŸæ˜¾ç¤º
    if 'Date' in grouped_df.columns and not grouped_df.empty:
        grouped_df['Date'] = grouped_df['Date'].astype(str)
    
    # æŒ‰æ—¥æœŸé™åºæ’åˆ—
    grouped_df = grouped_df.sort_values('Date', ascending=False)
    
    # é¸æ“‡è¦é¡¯ç¤ºçš„ä¸»è¦åˆ—
    display_columns = [
        'Date', 'Advertiser', 'Clicks', 'Conversions', 
        'Sale Amount (USD)', 'Estimated Earnings (USD)', 'Avg. Commission Rate (%)'
    ]
    
    # æº–å‚™æœ€çµ‚é¡¯ç¤ºçš„DataFrame
    final_df = grouped_df[display_columns].copy()
    
    # é»˜èªé¡¯ç¤º25æ¢è¨˜éŒ„
    records_to_show = 25
    display_df = final_df.head(records_to_show)
    
    # è¨ˆç®—ç¸½è¨ˆè¡Œ
    if len(grouped_df) > 0:
        # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        if 'Clicks' in grouped_df.columns:
            total_clicks = grouped_df['Clicks'].sum()
        else:
            total_clicks = 0
        
        if 'Conversions' in grouped_df.columns:
            # å¦‚æœ Conversions å·²ç»æ˜¯æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²ï¼Œéœ€è¦è½¬æ¢å›æ•°å­—
            if grouped_df['Conversions'].dtype == 'object':
                total_conversions = grouped_df['Conversions'].astype(str).str.replace(',', '').astype(int).sum()
            else:
                total_conversions = grouped_df['Conversions'].sum()
        else:
            total_conversions = 0
        
        total_sales = grouped_df['Sale_Amount'].sum()
        total_earnings = grouped_df['Earnings'].sum()
        overall_commission_rate = (total_earnings / total_sales * 100) if total_sales > 0 else 0
        
        # å‰µå»ºç¸½è¨ˆè¡Œ
        totals_row = pd.DataFrame({
            'Date': ['TOTAL'],
            'Advertiser': [''],
            'Clicks': [f"{total_clicks:,}"],
            'Conversions': [f"{total_conversions:,}"],
            'Sale Amount (USD)': [format_number(total_sales, "currency")],
            'Estimated Earnings (USD)': [format_number(total_earnings, "currency")],
            'Avg. Commission Rate (%)': [format_number(overall_commission_rate, "percentage")]
        })
        
        # åˆä½µç¸½è¨ˆè¡Œåˆ°é¡¯ç¤ºDataFrame
        display_with_totals = pd.concat([totals_row, display_df], ignore_index=True)
    else:
        display_with_totals = display_df
    
    # é¡¯ç¤ºè¡¨æ ¼
    st.dataframe(
        display_with_totals,
        use_container_width=True,
        hide_index=True,
        column_config={
            "Date": st.column_config.TextColumn("Date"),
            "Advertiser": st.column_config.TextColumn("Advertiser"),
            "Clicks": st.column_config.TextColumn("Clicks"),
            "Conversions": st.column_config.TextColumn("Conversions"),
            "Sale Amount (USD)": st.column_config.TextColumn("Sale Amount (USD)"),
            "Estimated Earnings (USD)": st.column_config.TextColumn("Estimated Earnings (USD)"),
            "Avg. Commission Rate (%)": st.column_config.TextColumn("Avg. Commission Rate (%)")
        }
    )
    
    # é¡¯ç¤ºè¨˜éŒ„æ•¸å’Œåˆ†é ä¿¡æ¯
    st.markdown("---")
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown(f"**Show:** 25")
        st.markdown(f"**Showing:** 1 to {min(records_to_show, len(final_df))} of {len(final_df)} entries")
    
    with col2:
        # åˆ†é æ§åˆ¶ï¼ˆç°¡åŒ–ç‰ˆï¼‰
        if len(final_df) > records_to_show:
            st.markdown("**Pages:** 1 2 3 ... Next")
    
    # ç§»é™¤èˆŠçš„çµ±è¨ˆä¿¡æ¯å’ŒCSVå°å‡ºï¼ˆå·²åœ¨é ‚éƒ¨å¯¦ç¾ï¼‰
    st.markdown("---")

def create_filters_section(data_manager: PostbackDataManager) -> Tuple[Optional[int], List[str], Tuple[datetime, datetime]]:
    """å‰µå»ºç¯©é¸å™¨å€åŸŸ"""
    st.markdown('<div class="filter-title">ğŸ¯ Filters</div>', unsafe_allow_html=True)
    st.markdown('<p class="sub-title">Filter your data by date range, platform, and offers.</p>', unsafe_allow_html=True)
    
    col1, col2, col3, col4 = st.columns([2, 2, 2, 2])
    
    with col1:
        st.markdown("**ğŸ“… Date Range**")
        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=7)
        
        date_range = st.date_input(
            "Select date range:",
            value=(start_date, end_date),
            max_value=end_date,
            label_visibility="collapsed"
        )
    
    with col2:
        st.markdown("**ğŸ¢ Platform**")
        platforms = data_manager.get_partners()
        
        platform_options = ["All Platforms"] + [f"{info['name']} ({info['code']})" for info in platforms.values()]
        
        selected_platform = st.selectbox(
            "Select platform:",
            options=platform_options,
            index=0,
            label_visibility="collapsed"
        )
        
        # æå–é¸ä¸­çš„ platform ID
        selected_platform_id = None
        if selected_platform != "All Platforms":
            for platform_id, info in platforms.items():
                if selected_platform == f"{info['name']} ({info['code']})":
                    selected_platform_id = info['id']
                    break
    
    with col3:
        st.markdown("**ğŸ¯ Offer Name**")
        offers = data_manager.get_offers_list(selected_platform_id)
        
        selected_offers = st.multiselect(
            "Select offers:",
            options=offers,
            default=[],
            label_visibility="collapsed"
        )
    
    with col4:
        st.markdown("**ğŸ”§ Actions**")
        
        col4_1, col4_2 = st.columns(2)
        
        with col4_1:
            if st.button("ğŸ” Search", type="primary"):
                st.rerun()
        
        with col4_2:
            if st.button("ğŸ”„ Reset"):
                st.rerun()
    
    return selected_platform_id, selected_offers, date_range

def create_ai_query_section(pandasai_manager: PandasAIManager, df: pd.DataFrame = None) -> None:
    """å‰µå»º AI æŸ¥è©¢å€åŸŸ"""
    st.markdown('<div class="ai-query-section">', unsafe_allow_html=True)
    st.markdown('<div class="ai-query-title">ğŸ¤– AI Smart Query Assistant</div>', unsafe_allow_html=True)
    
    # æŸ¥è©¢è¼¸å…¥
    col1, col2 = st.columns([4, 1])
    
    with col1:
        query_input = st.text_input(
            "AI Query Input",
            placeholder="Ask anything about your data... (e.g., 'Which offer performed best today?')",
            label_visibility="collapsed"
        )
    
    with col2:
        query_button = st.button("ğŸ” Query", type="primary")
    
    # å¿«é€ŸæŸ¥è©¢æŒ‰éˆ•
    st.markdown("ğŸ’¡ Quick Queries:")
    col1, col2, col3, col4 = st.columns(4)
    
    quick_queries = [
        ("ğŸ“Š Best Offer Today", "Which offer has the highest conversions today?"),
        ("ğŸ’° Top Revenue Source", "Which Source generated the most revenue?"),
        ("ğŸ“ˆ Platform Performance", "Which platform has the best conversion rates?"),
        ("ğŸ‘¥ Partner Analysis", "Which partner has the highest earnings?")
    ]
    
    for i, (label, query) in enumerate(quick_queries):
        with [col1, col2, col3, col4][i]:
            if st.button(label, key=f"quick_{i}"):
                query_input = query
                query_button = True
    
    # åŸ·è¡ŒæŸ¥è©¢
    if query_button and query_input:
        with st.spinner("ğŸ¤” AI is analyzing your query..."):
            if PANDASAI_AVAILABLE and pandasai_manager.llm:
                result, error = pandasai_manager.query_dataframe(query_input, "main")
                
                if error:
                    st.error(f"âŒ Query failed: {error}")
                else:
                    st.success("âœ… Query completed!")
                    
                    # é¡¯ç¤ºçµæœ
                    if isinstance(result, pd.DataFrame):
                        st.dataframe(result, use_container_width=True)
                    else:
                        st.write(result)
                    
                    # æª¢æŸ¥æ˜¯å¦æœ‰ç”Ÿæˆçš„åœ–è¡¨
                    charts_path = "charts/"
                    if os.path.exists(charts_path):
                        chart_files = [f for f in os.listdir(charts_path) if f.endswith('.png')]
                        if chart_files:
                            latest_chart = max(chart_files, key=lambda x: os.path.getctime(os.path.join(charts_path, x)))
                            st.image(os.path.join(charts_path, latest_chart), caption="AI Generated Chart")
            else:
                # ç°¡åŒ–ç‰ˆ AI æŸ¥è©¢
                if df is not None and not df.empty:
                    result = get_simple_ai_response(df, query_input)
                    st.success("âœ… Query completed!")
                    st.write(result)
                else:
                    st.error("âŒ No data available for AI analysis")
    
    if not PANDASAI_AVAILABLE:
        st.info("ğŸš§ Using simplified AI query mode (PandasAI not available)")
    elif not GEMINI_API_KEY:
        st.info("ğŸš§ Please configure Google Gemini API Key to enable AI query functionality")
    
    st.markdown('</div>', unsafe_allow_html=True)

def get_simple_ai_response(df: pd.DataFrame, query: str) -> str:
    """ç°¡åŒ–ç‰ˆ AI å›æ‡‰"""
    try:
        api_key = os.getenv("GOOGLE_GEMINI_API_KEY")
        if not api_key:
            return "è«‹è¨­ç½® GOOGLE_GEMINI_API_KEY ç’°å¢ƒè®Šé‡"
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-1.5-flash")
        
        # å‰µå»ºæ•¸æ“šæ¦‚è¦½
        if not df.empty:
            data_summary = f"""
            æ•¸æ“šæ¦‚è¦½ï¼š
            - ç¸½è¨˜éŒ„æ•¸ï¼š{len(df)}
            - åˆ—åï¼š{', '.join(df.columns.tolist())}
            - æ—¥æœŸç¯„åœï¼š{df['date'].min()} åˆ° {df['date'].max()}
            - ç¸½é»æ“Šæ•¸ï¼š{df['sub_id'].nunique() if 'sub_id' in df.columns else 0:,}
            - ç¸½è½‰åŒ–æ•¸ï¼š{df['conversion_value'].count() if 'conversion_value' in df.columns else 0:,}
            - ç¸½éŠ·å”®é¡ï¼š${df['conversion_value'].sum() if 'conversion_value' in df.columns else 0:,.2f}
            - ç¸½æ”¶ç›Šï¼š${df['payout'].sum() if 'payout' in df.columns else 0:,.2f}
            """
        else:
            data_summary = "æ•¸æ“šé›†ç‚ºç©º"
        
        prompt = f"""
        åŸºæ–¼ä»¥ä¸‹æ•¸æ“šå›ç­”ç”¨æˆ¶å•é¡Œï¼š
        {data_summary}
        
        ç”¨æˆ¶å•é¡Œï¼š{query}
        
        è«‹ç”¨ä¸­æ–‡å›ç­”ï¼Œä¸¦æä¾›å…·é«”çš„æ•¸æ“šåˆ†æã€‚
        """
        
        response = model.generate_content(prompt)
        return response.text if response else "ç„¡æ³•ç²å–å›æ‡‰"
    except Exception as e:
        return f"AI æŸ¥è©¢éŒ¯èª¤ï¼š{str(e)}"

def main():
    """ä¸»æ‡‰ç”¨ç¨‹åº"""
    # è¨­ç½®é é¢é…ç½®
    st.set_page_config(
        page_title="ByteC Network Analytics",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="collapsed"
    )
    
    # è¼‰å…¥è‡ªå®šç¾©CSS
    st.markdown(CUSTOM_CSS, unsafe_allow_html=True)
    
    # æ¨™é¡Œå€åŸŸ
    st.markdown('<h1 class="main-title">ByteC Performance Dashboard</h1>', unsafe_allow_html=True)
    
    # åˆå§‹åŒ–ç®¡ç†å™¨
    if 'data_manager' not in st.session_state:
        st.session_state.data_manager = PostbackDataManager()
    
    if 'pandasai_manager' not in st.session_state:
        st.session_state.pandasai_manager = PandasAIManager()
    
    data_manager = st.session_state.data_manager
    pandasai_manager = st.session_state.pandasai_manager
    
    # å‰µå»ºç¯©é¸å™¨å€åŸŸ
    selected_platform_id, selected_offers, date_range = create_filters_section(data_manager)
    
    # åˆ†éš”ç·š
    create_section_divider("space")
    
    # è¨ˆç®—æ—¥æœŸç¯„åœçš„å¤©æ•¸
    if isinstance(date_range, tuple) and len(date_range) == 2:
        start_date, end_date = date_range
        days_diff = (end_date - start_date).days + 1
    else:
        days_diff = 7
    
    # åŠ è¼‰æ•¸æ“š
    with st.spinner("ğŸ“¡ Loading data..."):
        try:
            # ç²å–æ€§èƒ½æŒ‡æ¨™
            metrics = data_manager.get_performance_metrics(days_diff, selected_platform_id)
            
            # ç²å–è©³ç´°æ•¸æ“š
            comprehensive_data = data_manager.get_comprehensive_data(days_diff, selected_platform_id)
            
            # å‰µå»º PandasAI æ™ºèƒ½æ•¸æ“šæ¡†
            if PANDASAI_AVAILABLE and not comprehensive_data.empty:
                pandasai_manager.create_smart_dataframe(comprehensive_data, "main")
            
        except Exception as e:
            st.error(f"âŒ Data loading failed: {str(e)}")
            return
    
    # å‰µå»ºæ€§èƒ½æ¦‚è¦½
    create_performance_overview(metrics)
    
    # ç©ºç™½åˆ†éš”ç·š
    create_section_divider("space")
    
    # ä¸»è¦åˆ†éš”ç·š
    create_section_divider("major")
    
    # å‰µå»ºå…¬å¸ç´šåˆ¥æ±‡æ€» (æ–°å¢)
    if isinstance(date_range, tuple) and len(date_range) == 2:
        create_company_level_summary(comprehensive_data, date_range[0], date_range[1])
    else:
        create_company_level_summary(comprehensive_data)
    
    # ä¸»è¦åˆ†éš”ç·š
    create_section_divider("major")
    
    # å‰µå»ºç¸½è¡¨å€åŸŸ
    create_summary_tables(comprehensive_data)

    # ä¸»è¦åˆ†éš”ç·š
    create_section_divider("major")
    
    # AI æŸ¥è©¢å€åŸŸ
    create_ai_query_section(pandasai_manager, comprehensive_data)
    
    # ä¸»è¦åˆ†éš”ç·š
    create_section_divider("major")
    
    # è©³ç´°å ±è¡¨
    create_detailed_report_table(comprehensive_data)
    
    # å´é‚Šæ¬„ä¿¡æ¯
    with st.sidebar:
        st.title("â„¹ï¸ Information")
        st.info(f"ğŸ“… Date Range: {days_diff} days")
        
        if selected_platform_id:
            platforms = data_manager.get_partners()
            platform_name = next((info['name'] for code, info in platforms.items() if info['id'] == selected_platform_id), "Unknown")
            st.info(f"ğŸ‘¥ Platform: {platform_name}")
        else:
            st.info("ğŸ‘¥ Platform: All Platforms")
        
        st.info(f"ğŸ“Š Total Records: {len(comprehensive_data)}")
        
        # åˆ·æ–°æŒ‰éˆ•
        if st.button("ğŸ”„ Refresh Data"):
            data_manager._cache.clear()
            data_manager._cache_timestamp.clear()
            st.rerun()

if __name__ == "__main__":
    main() 