#!/usr/bin/env python3
"""
æ•°æ®è¿ç§»è„šæœ¬ï¼šå°†å†…å­˜å­˜å‚¨çš„è½¬æ¢æ•°æ®è¿ç§»åˆ°PostgreSQLæ•°æ®åº“
"""

import asyncio
import json
import sys
import os
from datetime import datetime
from decimal import Decimal
import logging
import asyncpg
import requests

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ•°æ®åº“è¿æ¥é…ç½®
DATABASE_URL = "postgresql://postback:postback123@postback_postgres:5432/postback_db"  # ä½¿ç”¨å®¹å™¨åè¿æ¥
POSTBACK_API_URL = "https://bytec-public-postback-472712465571.asia-southeast1.run.app"


async def create_database_tables(conn):
    """åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„"""
    logger.info("åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„...")
    
    # åˆ›å»ºç§Ÿæˆ·è¡¨
    await conn.execute("""
        CREATE TABLE IF NOT EXISTS tenants (
            id SERIAL PRIMARY KEY,
            tenant_code VARCHAR(50) UNIQUE NOT NULL DEFAULT 'default',
            tenant_name VARCHAR(100) NOT NULL DEFAULT 'Default Tenant',
            ts_token VARCHAR(255),
            tlm_token VARCHAR(255),
            ts_param VARCHAR(100),
            description TEXT,
            contact_email VARCHAR(255),
            contact_phone VARCHAR(50),
            max_daily_requests INTEGER DEFAULT 100000,
            enable_duplicate_check BOOLEAN DEFAULT true,
            data_retention_days INTEGER DEFAULT 7,
            is_active BOOLEAN DEFAULT true,
            created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
        );
    """)
    
    # åˆ›å»ºè½¬åŒ–æ•°æ®è¡¨
    await conn.execute("""
        CREATE TABLE IF NOT EXISTS postback_conversions (
            id SERIAL PRIMARY KEY,
            tenant_id INTEGER REFERENCES tenants(id) ON DELETE CASCADE DEFAULT 1,
            
            -- Involve Asia æ ¸å¿ƒå­—æ®µ
            conversion_id VARCHAR(50) NOT NULL,
            offer_id VARCHAR(50),
            offer_name TEXT,
            
            -- æ—¶é—´å­—æ®µ
            datetime_conversion TIMESTAMP WITH TIME ZONE,
            datetime_conversion_updated TIMESTAMP WITH TIME ZONE,
            
            -- è®¢å•ä¿¡æ¯
            order_id VARCHAR(100),
            
            -- é‡‘é¢å­—æ®µ
            sale_amount_local DECIMAL(15,2),
            myr_sale_amount DECIMAL(15,2),
            usd_sale_amount DECIMAL(15,2),
            
            -- ä½£é‡‘å­—æ®µ
            payout_local DECIMAL(15,2),
            myr_payout DECIMAL(15,2),
            usd_payout DECIMAL(15,2),
            
            -- è´§å¸ä»£ç 
            conversion_currency VARCHAR(3),
            
            -- å¹¿å‘Šä¸»è‡ªå®šä¹‰å‚æ•°
            adv_sub VARCHAR(255),
            adv_sub2 VARCHAR(255),
            adv_sub3 VARCHAR(255),
            adv_sub4 VARCHAR(255),
            adv_sub5 VARCHAR(255),
            
            -- å‘å¸ƒå•†è‡ªå®šä¹‰å‚æ•°
            aff_sub VARCHAR(255),
            aff_sub2 VARCHAR(255),
            aff_sub3 VARCHAR(255),
            aff_sub4 VARCHAR(255),
            
            -- çŠ¶æ€å­—æ®µ
            status VARCHAR(50),
            offer_status VARCHAR(50),
            
            -- å¤„ç†çŠ¶æ€
            is_processed BOOLEAN DEFAULT false,
            is_duplicate BOOLEAN DEFAULT false,
            processing_error TEXT,
            
            -- åŸå§‹æ•°æ®
            raw_data JSONB,
            request_headers JSONB,
            request_ip VARCHAR(45),
            
            -- æ—¶é—´æˆ³
            received_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
            created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
        );
    """)
    
    # åˆ›å»ºç´¢å¼•
    await conn.execute("CREATE INDEX IF NOT EXISTS idx_postback_tenant_id ON postback_conversions(tenant_id);")
    await conn.execute("CREATE INDEX IF NOT EXISTS idx_postback_conversion_id ON postback_conversions(conversion_id);")
    await conn.execute("CREATE INDEX IF NOT EXISTS idx_postback_received_at ON postback_conversions(received_at);")
    
    # æ’å…¥é»˜è®¤ç§Ÿæˆ·
    await conn.execute("""
        INSERT INTO tenants (tenant_code, tenant_name, description, is_active)
        VALUES ('default', 'Default Tenant', 'Default tenant for postback data', true)
        ON CONFLICT (tenant_code) DO NOTHING;
    """)
    
    logger.info("æ•°æ®åº“è¡¨ç»“æ„åˆ›å»ºå®Œæˆ")


async def fetch_memory_data():
    """ä»å†…å­˜APIè·å–æ‰€æœ‰è½¬æ¢æ•°æ®"""
    logger.info("ä»postback APIè·å–å†…å­˜æ•°æ®...")
    
    try:
        # è·å–æ€»è®°å½•æ•°
        response = requests.get(f"{POSTBACK_API_URL}/postback/stats")
        response.raise_for_status()
        stats = response.json()
        total_records = stats.get('total_records', 0)
        
        logger.info(f"æ€»è®°å½•æ•°: {total_records}")
        
        # è·å–æ‰€æœ‰æ•°æ®
        response = requests.get(f"{POSTBACK_API_URL}/postback/conversions?limit={total_records + 100}")
        response.raise_for_status()
        data = response.json()
        
        records = data.get('records', [])
        logger.info(f"æˆåŠŸè·å– {len(records)} æ¡è®°å½•")
        
        return records
        
    except Exception as e:
        logger.error(f"è·å–å†…å­˜æ•°æ®å¤±è´¥: {str(e)}")
        return []


def safe_decimal(value, default=None):
    """å®‰å…¨è½¬æ¢ä¸ºDecimalç±»å‹"""
    if value is None:
        return default
    try:
        if isinstance(value, str):
            if value.strip() == '' or value.lower() in ['null', 'none']:
                return default
        return Decimal(str(value))
    except:
        return default


def safe_datetime(value):
    """å®‰å…¨è½¬æ¢ä¸ºdatetimeç±»å‹"""
    if not value:
        return None
    try:
        # å°è¯•è§£æä¸åŒæ ¼å¼çš„æ—¶é—´
        formats = [
            '%Y-%m-%d %H:%M:%S',
            '%Y-%m-%dT%H:%M:%S',
            '%Y-%m-%dT%H:%M:%SZ',
            '%Y-%m-%d %H:%M:%S.%f',
        ]
        
        for fmt in formats:
            try:
                return datetime.strptime(value, fmt)
            except:
                continue
        
        return None
    except:
        return None


async def migrate_records(conn, records):
    """è¿ç§»è½¬æ¢è®°å½•åˆ°PostgreSQL"""
    logger.info(f"å¼€å§‹è¿ç§» {len(records)} æ¡è®°å½•...")
    
    migrated = 0
    errors = 0
    
    for i, record in enumerate(records, 1):
        try:
            data = record.get('data', {})
            
            # å‡†å¤‡æ•°æ®
            conversion_data = {
                'conversion_id': data.get('conversion_id', f'migrated_{i}'),
                'offer_name': data.get('offer_name'),
                'usd_sale_amount': safe_decimal(data.get('usd_sale_amount')),
                'usd_payout': safe_decimal(data.get('usd_payout')),
                'aff_sub': data.get('aff_sub'),
                'aff_sub2': data.get('aff_sub2'),
                'aff_sub3': data.get('aff_sub3'),
                'datetime_conversion': safe_datetime(data.get('datetime_conversion')),
                'raw_data': json.dumps(data),
                'received_at': datetime.fromtimestamp(record.get('timestamp', 0)),
                'is_processed': True,
                'request_ip': '127.0.0.1'  # é»˜è®¤IP
            }
            
            # æ’å…¥æ•°æ®
            await conn.execute("""
                INSERT INTO postback_conversions (
                    tenant_id, conversion_id, offer_name, usd_sale_amount, usd_payout,
                    aff_sub, aff_sub2, aff_sub3, datetime_conversion, raw_data,
                    received_at, is_processed, request_ip
                ) VALUES (
                    1, $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12
                ) ON CONFLICT (conversion_id) DO NOTHING
            """, 
                conversion_data['conversion_id'],
                conversion_data['offer_name'],
                conversion_data['usd_sale_amount'],
                conversion_data['usd_payout'],
                conversion_data['aff_sub'],
                conversion_data['aff_sub2'],
                conversion_data['aff_sub3'],
                conversion_data['datetime_conversion'],
                conversion_data['raw_data'],
                conversion_data['received_at'],
                conversion_data['is_processed'],
                conversion_data['request_ip']
            )
            
            migrated += 1
            
            if i % 50 == 0:
                logger.info(f"å·²è¿ç§» {i}/{len(records)} æ¡è®°å½•...")
                
        except Exception as e:
            logger.error(f"è¿ç§»ç¬¬ {i} æ¡è®°å½•å¤±è´¥: {str(e)}")
            errors += 1
            continue
    
    logger.info(f"è¿ç§»å®Œæˆï¼æˆåŠŸ: {migrated} æ¡ï¼Œå¤±è´¥: {errors} æ¡")
    return migrated, errors


async def verify_migration(conn):
    """éªŒè¯è¿ç§»ç»“æœ"""
    logger.info("éªŒè¯è¿ç§»ç»“æœ...")
    
    # ç»Ÿè®¡æ€»è®°å½•æ•°
    total = await conn.fetchval("SELECT COUNT(*) FROM postback_conversions")
    
    # ç»Ÿè®¡ä¸åŒçŠ¶æ€çš„è®°å½•
    with_amounts = await conn.fetchval(
        "SELECT COUNT(*) FROM postback_conversions WHERE usd_sale_amount IS NOT NULL"
    )
    
    recent = await conn.fetchval(
        "SELECT COUNT(*) FROM postback_conversions WHERE received_at >= NOW() - INTERVAL '1 day'"
    )
    
    # è·å–æ ·æœ¬æ•°æ®
    sample = await conn.fetch(
        "SELECT conversion_id, offer_name, usd_sale_amount, usd_payout, received_at FROM postback_conversions ORDER BY received_at DESC LIMIT 5"
    )
    
    logger.info(f"éªŒè¯ç»“æœ:")
    logger.info(f"  æ€»è®°å½•æ•°: {total}")
    logger.info(f"  æœ‰é‡‘é¢æ•°æ®: {with_amounts}")
    logger.info(f"  æœ€è¿‘24å°æ—¶: {recent}")
    logger.info(f"  æœ€æ–°5æ¡è®°å½•:")
    
    for row in sample:
        logger.info(f"    {row['conversion_id']} | {row['offer_name']} | ${row['usd_sale_amount']} | {row['received_at']}")


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æ•°æ®è¿ç§»åˆ°PostgreSQL...")
    
    try:
        # è¿æ¥æ•°æ®åº“
        logger.info("è¿æ¥PostgreSQLæ•°æ®åº“...")
        conn = await asyncpg.connect(DATABASE_URL)
        
        # åˆ›å»ºè¡¨ç»“æ„
        await create_database_tables(conn)
        
        # è·å–å†…å­˜æ•°æ®
        records = await fetch_memory_data()
        
        if not records:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°éœ€è¦è¿ç§»çš„æ•°æ®")
            return
        
        # è¿ç§»æ•°æ®
        migrated, errors = await migrate_records(conn, records)
        
        # éªŒè¯ç»“æœ
        await verify_migration(conn)
        
        # å…³é—­è¿æ¥
        await conn.close()
        
        logger.info("ğŸ‰ æ•°æ®è¿ç§»å®Œæˆï¼")
        logger.info(f"ğŸ“Š è¿ç§»ç»Ÿè®¡: æˆåŠŸ {migrated} æ¡ï¼Œå¤±è´¥ {errors} æ¡")
        
    except Exception as e:
        logger.error(f"âŒ è¿ç§»è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main()) 