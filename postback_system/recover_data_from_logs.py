#!/usr/bin/env python3
"""
ä»Cloud Runæ—¥å¿—ä¸­æå–è½¬åŒ–æ•°æ®å¹¶æ¢å¤åˆ°æ•°æ®åº“
"""

import asyncio
import asyncpg
import re
import json
import subprocess
from datetime import datetime, timedelta
from decimal import Decimal
from urllib.parse import unquote
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ•°æ®åº“è¿æ¥é…ç½®
DATABASE_URL = "postgresql://postback_admin:ByteC2024PostBack_CloudSQL_20250708@/postback_db?host=/cloudsql/solar-idea-463423-h8:asia-southeast1:bytec-postback-db&sslmode=require"

# Cloud Runé…ç½®
PROJECT_ID = "solar-idea-463423-h8"
SERVICE_NAME = "bytec-public-postback"
REGION = "asia-southeast1"

def extract_postback_data_from_log(log_line):
    """ä»æ—¥å¿—è¡Œä¸­æå–postbackæ•°æ®"""
    try:
        # æŸ¥æ‰¾involve/eventçš„GETè¯·æ±‚
        involve_pattern = r'GET /involve/event\?([^"]+)'
        match = re.search(involve_pattern, log_line)
        
        if not match:
            return None
        
        # è§£ææŸ¥è¯¢å‚æ•°
        query_string = match.group(1)
        params = {}
        
        for param_pair in query_string.split('&'):
            if '=' in param_pair:
                key, value = param_pair.split('=', 1)
                params[key] = unquote(value)
        
        # æå–æ—¶é—´æˆ³
        timestamp_pattern = r'(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2})'
        timestamp_match = re.search(timestamp_pattern, log_line)
        received_at = None
        if timestamp_match:
            try:
                received_at = datetime.fromisoformat(timestamp_match.group(1) + 'Z').replace(tzinfo=None)
            except:
                received_at = datetime.now()
        
        # è½¬æ¢æ•°æ®ç±»å‹
        conversion_data = {
            'conversion_id': params.get('conversion_id'),
            'offer_name': params.get('offer_name', ''),
            'usd_sale_amount': safe_decimal(params.get('usd_sale_amount')),
            'usd_payout': safe_decimal(params.get('usd_payout')),
            'sub_id': params.get('sub_id', ''),
            'media_id': params.get('media_id', ''),
            'click_id': params.get('click_id', ''),
            'datetime_conversion': safe_datetime(params.get('datetime_conversion')),
            'received_at': received_at or datetime.now(),
            'raw_data': json.dumps(params)
        }
        
        return conversion_data
        
    except Exception as e:
        logger.error(f"è§£ææ—¥å¿—è¡Œå¤±è´¥: {str(e)} - {log_line[:100]}")
        return None

def safe_decimal(value):
    """å®‰å…¨è½¬æ¢ä¸ºDecimal"""
    if not value:
        return None
    try:
        return Decimal(str(value))
    except:
        return None

def safe_datetime(value):
    """å®‰å…¨è½¬æ¢ä¸ºdatetime"""
    if not value:
        return None
    try:
        # æ›¿æ¢URLç¼–ç çš„å­—ç¬¦
        value = value.replace('%3A', ':').replace('%20', ' ')
        return datetime.strptime(value, '%Y-%m-%d %H:%M:%S')
    except:
        return None

async def fetch_logs_from_gcloud(hours=24):
    """ä»gcloudè·å–æ—¥å¿—"""
    logger.info(f"è·å–è¿‡å»{hours}å°æ—¶çš„Cloud Runæ—¥å¿—...")
    
    try:
        # æ„å»ºgcloudå‘½ä»¤
        cmd = [
            'gcloud', 'logging', 'read',
            f'resource.type="cloud_run_revision" AND resource.labels.service_name="{SERVICE_NAME}" AND textPayload:"/involve/event"',
            f'--limit=1000',
            f'--freshness={hours}h',
            '--format=value(timestamp,textPayload)',
            '--project', PROJECT_ID
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            logger.error(f"gcloudå‘½ä»¤å¤±è´¥: {result.stderr}")
            return []
        
        logs = []
        for line in result.stdout.strip().split('\n'):
            if line.strip():
                logs.append(line.strip())
        
        logger.info(f"è·å–åˆ°{len(logs)}æ¡æ—¥å¿—è®°å½•")
        return logs
        
    except Exception as e:
        logger.error(f"è·å–æ—¥å¿—å¤±è´¥: {str(e)}")
        return []

async def create_tables_if_not_exist(conn):
    """åˆ›å»ºè¡¨ç»“æ„ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰"""
    logger.info("æ£€æŸ¥å¹¶åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„...")
    
    # åˆ›å»ºç§Ÿæˆ·è¡¨
    await conn.execute("""
        CREATE TABLE IF NOT EXISTS tenants (
            id SERIAL PRIMARY KEY,
            tenant_code VARCHAR(50) UNIQUE NOT NULL DEFAULT 'default',
            tenant_name VARCHAR(100) NOT NULL DEFAULT 'Default Tenant',
            description TEXT,
            is_active BOOLEAN DEFAULT true,
            created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
        );
    """)
    
    # åˆ›å»ºè½¬æ¢è¡¨
    await conn.execute("""
        CREATE TABLE IF NOT EXISTS conversions (
            id SERIAL PRIMARY KEY,
            tenant_id INTEGER DEFAULT 1,
            conversion_id VARCHAR(255) NOT NULL,
            offer_name VARCHAR(255),
            usd_sale_amount DECIMAL(15,2),
            usd_payout DECIMAL(15,2),
            sub_id VARCHAR(255),
            media_id VARCHAR(255),
            click_id VARCHAR(255),
            datetime_conversion TIMESTAMP WITH TIME ZONE,
            raw_data JSONB,
            received_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
            created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(conversion_id)
        );
    """)
    
    # åˆ›å»ºç´¢å¼•
    await conn.execute("CREATE INDEX IF NOT EXISTS idx_conversions_conversion_id ON conversions(conversion_id);")
    await conn.execute("CREATE INDEX IF NOT EXISTS idx_conversions_received_at ON conversions(received_at);")
    
    # æ’å…¥é»˜è®¤ç§Ÿæˆ·
    await conn.execute("""
        INSERT INTO tenants (tenant_code, tenant_name, description)
        VALUES ('default', 'Default Tenant', 'Default tenant for recovered data')
        ON CONFLICT (tenant_code) DO NOTHING;
    """)
    
    logger.info("æ•°æ®åº“è¡¨ç»“æ„æ£€æŸ¥å®Œæˆ")

async def insert_conversion_data(conn, conversion_data):
    """æ’å…¥è½¬æ¢æ•°æ®åˆ°æ•°æ®åº“"""
    try:
        await conn.execute("""
            INSERT INTO conversions (
                conversion_id, offer_name, usd_sale_amount, usd_payout,
                sub_id, media_id, click_id, datetime_conversion,
                raw_data, received_at
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
            ON CONFLICT (conversion_id) DO UPDATE SET
                offer_name = EXCLUDED.offer_name,
                usd_sale_amount = EXCLUDED.usd_sale_amount,
                usd_payout = EXCLUDED.usd_payout,
                sub_id = EXCLUDED.sub_id,
                media_id = EXCLUDED.media_id,
                click_id = EXCLUDED.click_id,
                datetime_conversion = EXCLUDED.datetime_conversion,
                raw_data = EXCLUDED.raw_data,
                received_at = EXCLUDED.received_at
        """, 
            conversion_data['conversion_id'],
            conversion_data['offer_name'],
            conversion_data['usd_sale_amount'],
            conversion_data['usd_payout'],
            conversion_data['sub_id'],
            conversion_data['media_id'],
            conversion_data['click_id'],
            conversion_data['datetime_conversion'],
            conversion_data['raw_data'],
            conversion_data['received_at']
        )
        return True
    except Exception as e:
        logger.error(f"æ’å…¥æ•°æ®å¤±è´¥: {str(e)} - {conversion_data.get('conversion_id', 'unknown')}")
        return False

async def recover_data():
    """ä¸»æ¢å¤å‡½æ•°"""
    logger.info("å¼€å§‹ä»æ—¥å¿—æ¢å¤è½¬åŒ–æ•°æ®...")
    
    # è·å–æ—¥å¿—
    logs = await fetch_logs_from_gcloud(hours=48)  # è·å–è¿‡å»48å°æ—¶çš„æ—¥å¿—
    
    if not logs:
        logger.warning("æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—æ•°æ®")
        return
    
    # è§£æè½¬åŒ–æ•°æ®
    conversions = []
    for log_line in logs:
        conversion_data = extract_postback_data_from_log(log_line)
        if conversion_data and conversion_data.get('conversion_id'):
            conversions.append(conversion_data)
    
    logger.info(f"ä»æ—¥å¿—ä¸­æå–åˆ°{len(conversions)}æ¡è½¬åŒ–è®°å½•")
    
    if not conversions:
        logger.warning("æ²¡æœ‰æå–åˆ°æœ‰æ•ˆçš„è½¬åŒ–æ•°æ®")
        return
    
    # å»é‡
    unique_conversions = {}
    for conv in conversions:
        conv_id = conv['conversion_id']
        if conv_id not in unique_conversions:
            unique_conversions[conv_id] = conv
        else:
            # ä¿ç•™æœ€æ–°çš„è®°å½•
            if conv['received_at'] > unique_conversions[conv_id]['received_at']:
                unique_conversions[conv_id] = conv
    
    conversions = list(unique_conversions.values())
    logger.info(f"å»é‡åæœ‰{len(conversions)}æ¡å”¯ä¸€è½¬åŒ–è®°å½•")
    
    # è¿æ¥æ•°æ®åº“
    try:
        conn = await asyncpg.connect(DATABASE_URL)
        logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        # åˆ›å»ºè¡¨ç»“æ„
        await create_tables_if_not_exist(conn)
        
        # æ’å…¥æ•°æ®
        success_count = 0
        error_count = 0
        
        for conversion_data in conversions:
            if await insert_conversion_data(conn, conversion_data):
                success_count += 1
            else:
                error_count += 1
        
        logger.info(f"æ•°æ®æ¢å¤å®Œæˆ: æˆåŠŸ{success_count}æ¡ï¼Œå¤±è´¥{error_count}æ¡")
        
        # éªŒè¯ç»“æœ
        total_count = await conn.fetchval("SELECT COUNT(*) FROM conversions")
        today_count = await conn.fetchval("SELECT COUNT(*) FROM conversions WHERE DATE(received_at) = CURRENT_DATE")
        total_amount = await conn.fetchval("SELECT SUM(usd_sale_amount) FROM conversions WHERE usd_sale_amount IS NOT NULL")
        
        logger.info(f"éªŒè¯ç»“æœ:")
        logger.info(f"  æ•°æ®åº“æ€»è®°å½•æ•°: {total_count}")
        logger.info(f"  ä»Šå¤©çš„è®°å½•æ•°: {today_count}")
        logger.info(f"  æ€»é”€å”®é‡‘é¢: ${total_amount:.2f}" if total_amount else "  æ€»é”€å”®é‡‘é¢: $0.00")
        
        await conn.close()
        
    except Exception as e:
        logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {str(e)}")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ä»æ—¥å¿—æ¢å¤postbackè½¬åŒ–æ•°æ®...")
    print("-" * 60)
    
    await recover_data()
    
    print("\nâœ… æ•°æ®æ¢å¤ä»»åŠ¡å®Œæˆ!")

if __name__ == "__main__":
    asyncio.run(main()) 