#!/usr/bin/env python3
"""
Metabaseé›†æˆå’Œè‡ªç„¶è¯­è¨€æŸ¥è¯¢è§£å†³æ–¹æ¡ˆ
"""

import requests
import json
import openai
import os
from typing import Dict, Any, List
import asyncpg
import asyncio

class MetabaseIntegration:
    def __init__(self, metabase_url: str, username: str, password: str):
        self.metabase_url = metabase_url
        self.session = requests.Session()
        self.authenticate(username, password)
    
    def authenticate(self, username: str, password: str):
        """è®¤è¯åˆ°Metabase"""
        auth_data = {
            "username": username,
            "password": password
        }
        response = self.session.post(f"{self.metabase_url}/api/session", json=auth_data)
        if response.status_code == 200:
            token = response.json()['id']
            self.session.headers.update({'X-Metabase-Session': token})
        else:
            raise Exception("Metabaseè®¤è¯å¤±è´¥")
    
    def create_dashboard(self, name: str, description: str) -> int:
        """åˆ›å»ºæ–°çš„ä»ªè¡¨æ¿"""
        dashboard_data = {
            "name": name,
            "description": description
        }
        response = self.session.post(f"{self.metabase_url}/api/dashboard", json=dashboard_data)
        return response.json()['id']
    
    def execute_query(self, sql: str, database_id: int = 1) -> Dict[str, Any]:
        """æ‰§è¡ŒSQLæŸ¥è¯¢"""
        query_data = {
            "type": "native",
            "native": {
                "query": sql
            },
            "database": database_id
        }
        response = self.session.post(f"{self.metabase_url}/api/dataset", json=query_data)
        return response.json()


class NaturalLanguageQueryProcessor:
    def __init__(self, openai_api_key: str, db_schema: Dict[str, Any]):
        openai.api_key = openai_api_key
        self.db_schema = db_schema
    
    def natural_language_to_sql(self, question: str) -> str:
        """å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºSQLæŸ¥è¯¢"""
        schema_context = self._generate_schema_context()
        
        prompt = f"""
        æ•°æ®åº“æ¶æ„:
        {schema_context}
        
        ç”¨æˆ·é—®é¢˜: {question}
        
        è¯·æ ¹æ®ä¸Šè¿°æ•°æ®åº“æ¶æ„ï¼Œå°†ç”¨æˆ·é—®é¢˜è½¬æ¢ä¸ºPostgreSQLæŸ¥è¯¢è¯­å¥ã€‚
        åªè¿”å›SQLè¯­å¥ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚
        
        SQL:
        """
        
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„SQLæŸ¥è¯¢ç”ŸæˆåŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=500,
            temperature=0.1
        )
        
        return response.choices[0].message.content.strip()
    
    def _generate_schema_context(self) -> str:
        """ç”Ÿæˆæ•°æ®åº“æ¶æ„ä¸Šä¸‹æ–‡"""
        context = "è¡¨å: conversions\nå­—æ®µ:\n"
        for field, field_type in self.db_schema.items():
            context += f"- {field}: {field_type}\n"
        return context


class CursorCLITools:
    def __init__(self, db_url: str, supabase_url: str = None, supabase_key: str = None):
        self.db_url = db_url
        self.supabase_url = supabase_url
        self.supabase_key = supabase_key
        self.nl_processor = None
    
    async def setup_nl_processor(self, openai_key: str):
        """è®¾ç½®è‡ªç„¶è¯­è¨€å¤„ç†å™¨"""
        schema = {
            "id": "SERIAL PRIMARY KEY",
            "conversion_id": "VARCHAR(255)",
            "sub_id": "VARCHAR(255)",
            "media_id": "VARCHAR(255)",
            "click_id": "VARCHAR(255)",
            "usd_sale_amount": "DECIMAL(15,2)",
            "usd_payout": "DECIMAL(15,2)",
            "offer_name": "VARCHAR(500)",
            "datetime_conversion": "TIMESTAMP WITH TIME ZONE",
            "created_at": "TIMESTAMP WITH TIME ZONE"
        }
        self.nl_processor = NaturalLanguageQueryProcessor(openai_key, schema)
    
    async def execute_nl_query(self, question: str) -> List[Dict[str, Any]]:
        """æ‰§è¡Œè‡ªç„¶è¯­è¨€æŸ¥è¯¢"""
        if not self.nl_processor:
            raise Exception("è¯·å…ˆè®¾ç½®OpenAI APIå¯†é’¥")
        
        sql = self.nl_processor.natural_language_to_sql(question)
        return await self.execute_sql(sql)
    
    async def execute_sql(self, sql: str) -> List[Dict[str, Any]]:
        """æ‰§è¡ŒSQLæŸ¥è¯¢"""
        conn = await asyncpg.connect(self.db_url)
        try:
            rows = await conn.fetch(sql)
            return [dict(row) for row in rows]
        finally:
            await conn.close()
    
    def sync_to_supabase(self, data: List[Dict[str, Any]]):
        """åŒæ­¥æ•°æ®åˆ°Supabase"""
        if not self.supabase_url or not self.supabase_key:
            raise Exception("Supabaseé…ç½®ç¼ºå¤±")
        
        headers = {
            "apikey": self.supabase_key,
            "Authorization": f"Bearer {self.supabase_key}",
            "Content-Type": "application/json"
        }
        
        for record in data:
            response = requests.post(
                f"{self.supabase_url}/rest/v1/conversions",
                headers=headers,
                json=record
            )
            if response.status_code not in [200, 201]:
                print(f"åŒæ­¥å¤±è´¥: {response.text}")


# CLIå‘½ä»¤è¡Œå·¥å…·
class PostbackCLI:
    def __init__(self):
        self.tools = CursorCLITools(
            db_url="postgresql://postback:postback123@localhost:5432/postback_db"
        )
    
    async def ask(self, question: str):
        """è‡ªç„¶è¯­è¨€æŸ¥è¯¢æ¥å£"""
        print(f"ğŸ¤” é—®é¢˜: {question}")
        
        # è®¾ç½®OpenAIå¯†é’¥ï¼ˆä»ç¯å¢ƒå˜é‡è·å–ï¼‰
        openai_key = os.getenv('OPENAI_API_KEY')
        if not openai_key:
            print("âŒ è¯·è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
            return
        
        await self.tools.setup_nl_processor(openai_key)
        
        try:
            results = await self.tools.execute_nl_query(question)
            print(f"ğŸ“Š æŸ¥è¯¢ç»“æœ ({len(results)} æ¡è®°å½•):")
            
            if results:
                # æ˜¾ç¤ºå‰5æ¡è®°å½•
                for i, record in enumerate(results[:5]):
                    print(f"  {i+1}. {record}")
                
                if len(results) > 5:
                    print(f"  ... è¿˜æœ‰ {len(results) - 5} æ¡è®°å½•")
            else:
                print("  æ— æ•°æ®")
                
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}")
    
    async def stats(self):
        """æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡"""
        sql = """
        SELECT 
            COUNT(*) as total_conversions,
            COUNT(usd_sale_amount) as with_amount,
            SUM(usd_sale_amount) as total_sales,
            AVG(usd_sale_amount) as avg_sales,
            MAX(created_at) as latest_conversion
        FROM conversions
        """
        
        try:
            results = await self.tools.execute_sql(sql)
            stats = results[0]
            
            print("ğŸ“ˆ Postbackæ•°æ®ç»Ÿè®¡:")
            print(f"  æ€»è½¬æ¢æ•°: {stats['total_conversions']}")
            print(f"  æœ‰é‡‘é¢è®°å½•: {stats['with_amount']}")
            print(f"  æ€»é”€å”®é¢: ${stats['total_sales'] or 0:.2f}")
            print(f"  å¹³å‡é”€å”®é¢: ${stats['avg_sales'] or 0:.2f}")
            print(f"  æœ€æ–°è½¬æ¢: {stats['latest_conversion']}")
            
        except Exception as e:
            print(f"âŒ ç»Ÿè®¡å¤±è´¥: {str(e)}")


# ä½¿ç”¨ç¤ºä¾‹
async def main():
    cli = PostbackCLI()
    
    # è‡ªç„¶è¯­è¨€æŸ¥è¯¢ç¤ºä¾‹
    await cli.ask("æ˜¾ç¤ºæœ€è¿‘10æ¡è½¬æ¢è®°å½•")
    await cli.ask("å“ªä¸ªofferçš„è½¬æ¢ç‡æœ€é«˜ï¼Ÿ")
    await cli.ask("ä»Šå¤©æœ‰å¤šå°‘è½¬æ¢ï¼Ÿ")
    await cli.ask("é”€å”®é¢è¶…è¿‡100ç¾å…ƒçš„è½¬æ¢æœ‰å“ªäº›ï¼Ÿ")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    await cli.stats()


if __name__ == "__main__":
    asyncio.run(main()) 