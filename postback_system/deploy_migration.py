#!/usr/bin/env python3
"""
ç®€åŒ–çš„Cloud Runæ•°æ®è¿ç§»è„šæœ¬
"""

import asyncio
import json
import os
import sys
from datetime import datetime
from decimal import Decimal
import logging
import asyncpg

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Cloud SQLè¿æ¥é…ç½® (ä½¿ç”¨Unix socket)
DATABASE_URL = os.environ.get(
    'DATABASE_URL',
    'postgresql://postback_admin:ByteC2024PostBack_CloudSQL_20250708@/postback_db?host=/cloudsql/solar-idea-463423-h8:asia-southeast1:bytec-postback-db&sslmode=require'
)

async def create_database_tables(conn):
    """åˆ›å»ºç®€åŒ–çš„æ•°æ®åº“è¡¨ç»“æ„"""
    logger.info("åˆ›å»ºç®€åŒ–æ•°æ®åº“è¡¨ç»“æ„...")
    
    # åˆ é™¤ç°æœ‰è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    await conn.execute("DROP TABLE IF EXISTS conversions CASCADE;")
    await conn.execute("DROP TABLE IF EXISTS tenants CASCADE;")
    
    # åˆ›å»ºç§Ÿæˆ·è¡¨
    await conn.execute("""
        CREATE TABLE tenants (
            id SERIAL PRIMARY KEY,
            tenant_code VARCHAR(50) UNIQUE NOT NULL,
            tenant_name VARCHAR(255),
            description TEXT,
            is_active BOOLEAN DEFAULT true,
            created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
        );
    """)
    
    # åˆ›å»ºè½¬æ¢è¡¨ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
    await conn.execute("""
        CREATE TABLE conversions (
            id SERIAL PRIMARY KEY,
            tenant_id INTEGER DEFAULT 1,
            conversion_id VARCHAR(255) UNIQUE NOT NULL,
            offer_name VARCHAR(255),
            usd_sale_amount DECIMAL(15,2),
            usd_payout DECIMAL(15,2),
            aff_sub VARCHAR(255),
            event_time TIMESTAMP WITH TIME ZONE,
            raw_data JSONB,
            created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
        );
    """)
    
    # åˆ›å»ºç´¢å¼•
    await conn.execute("CREATE INDEX idx_conversions_conversion_id ON conversions(conversion_id);")
    await conn.execute("CREATE INDEX idx_conversions_created_at ON conversions(created_at);")
    
    # æ’å…¥é»˜è®¤ç§Ÿæˆ·
    await conn.execute("""
        INSERT INTO tenants (tenant_code, tenant_name, description)
        VALUES ('default', 'Default Tenant', 'Default tenant for migration')
        ON CONFLICT (tenant_code) DO NOTHING;
    """)
    
    logger.info("ç®€åŒ–è¡¨ç»“æ„åˆ›å»ºå®Œæˆ")

def safe_decimal(value, default=None):
    """å®‰å…¨è½¬æ¢ä¸ºDecimalç±»å‹"""
    if value is None:
        return default
    try:
        if isinstance(value, str):
            if value.strip() == '' or value.lower() in ['null', 'none']:
                return default
        return Decimal(str(value))
    except:
        return default

def safe_datetime(value):
    """å®‰å…¨è½¬æ¢ä¸ºdatetimeç±»å‹"""
    if not value:
        return None
    try:
        formats = [
            '%Y-%m-%d %H:%M:%S',
            '%Y-%m-%dT%H:%M:%S',
            '%Y-%m-%dT%H:%M:%SZ',
            '%Y-%m-%d %H:%M:%S.%f',
        ]
        
        for fmt in formats:
            try:
                return datetime.strptime(value, fmt)
            except:
                continue
        return None
    except:
        return None

async def migrate_from_json(conn):
    """ä»JSONæ•°æ®è¿ç§»"""
    logger.info("å¼€å§‹ä»JSONæ•°æ®è¿ç§»...")
    
    try:
        # åŠ è½½JSONæ•°æ®æ–‡ä»¶
        with open('/app/complete_migration_data.json', 'r', encoding='utf-8') as f:
            json_data = json.load(f)
        
        records = json_data.get('records', [])
        logger.info(f"ä»JSONæ–‡ä»¶åŠ è½½äº† {len(records)} æ¡è®°å½•")
        
        migrated = 0
        errors = 0
        
        for i, record in enumerate(records, 1):
            try:
                data = record.get('data', {})
                
                # å‡†å¤‡æ•°æ®
                conversion_id = data.get('conversion_id', '')
                if not conversion_id:
                    logger.warning(f"è®°å½• {i} ç¼ºå°‘conversion_idï¼Œè·³è¿‡")
                    errors += 1
                    continue
                
                # è§£æé‡‘é¢
                usd_sale_amount = safe_decimal(data.get('usd_sale_amount'))
                usd_payout = safe_decimal(data.get('usd_payout'))
                rewards = safe_decimal(data.get('rewards'))
                
                # è§£ææ—¶é—´
                datetime_conversion = safe_datetime(data.get('raw_params', {}).get('datetime_conversion'))
                event_time = safe_datetime(data.get('event_time'))
                
                # ç®€åŒ–æ•°æ®æ’å…¥
                await conn.execute("""
                    INSERT INTO conversions (
                        conversion_id, offer_name, usd_sale_amount, usd_payout,
                        aff_sub, raw_data
                    ) VALUES ($1, $2, $3, $4, $5, $6)
                    ON CONFLICT (conversion_id) DO NOTHING
                """, 
                    conversion_id,
                    data.get('offer_name', ''),
                    float(data.get('usd_sale_amount', 0)) if data.get('usd_sale_amount') else None,
                    float(data.get('usd_payout', 0)) if data.get('usd_payout') else None,
                    data.get('aff_sub', ''),
                    json.dumps(data)
                )
                
                migrated += 1
                
                if i % 100 == 0:
                    logger.info(f"å·²å¤„ç† {i}/{len(records)} æ¡è®°å½•")
                    
            except Exception as e:
                logger.error(f"è¿ç§»è®°å½• {i} å¤±è´¥: {str(e)}")
                errors += 1
        
        logger.info(f"è¿ç§»å®Œæˆ: æˆåŠŸ {migrated} æ¡ï¼Œå¤±è´¥ {errors} æ¡")
        return migrated, errors
        
    except FileNotFoundError:
        logger.error("æ‰¾ä¸åˆ°complete_migration_data.jsonæ–‡ä»¶")
        return 0, 1
    except Exception as e:
        logger.error(f"è¿ç§»è¿‡ç¨‹å‡ºé”™: {str(e)}")
        return 0, 1

async def verify_migration(conn):
    """éªŒè¯è¿ç§»ç»“æœ"""
    logger.info("éªŒè¯è¿ç§»ç»“æœ...")
    
    # æ£€æŸ¥è®°å½•æ•°
    count = await conn.fetchval("SELECT COUNT(*) FROM conversions")
    logger.info(f"æ€»è®°å½•æ•°: {count}")
    
    # æ£€æŸ¥æ•°æ®ç¤ºä¾‹
    samples = await conn.fetch("SELECT * FROM conversions LIMIT 3")
    for sample in samples:
        logger.info(f"ç¤ºä¾‹è®°å½•: ID={sample['id']}, è½¬æ¢ID={sample['conversion_id']}, é‡‘é¢=${sample['usd_sale_amount']}")

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹Cloud SQLæ•°æ®è¿ç§»...")
    
    try:
        # è¿æ¥æ•°æ®åº“
        logger.info("è¿æ¥Cloud SQLæ•°æ®åº“...")
        
        # æ ¹æ®ç¯å¢ƒä½¿ç”¨ä¸åŒçš„è¿æ¥æ–¹å¼
        if 'cloudsql' in DATABASE_URL:
            # Cloud Runç¯å¢ƒï¼Œä½¿ç”¨Unix socket
            conn = await asyncpg.connect(DATABASE_URL)
        else:
            # æœ¬åœ°ç¯å¢ƒï¼Œä½¿ç”¨ç›´æ¥è¿æ¥
            conn = await asyncpg.connect(DATABASE_URL)
        
        logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸï¼")
        
        # åˆ›å»ºè¡¨ç»“æ„
        await create_database_tables(conn)
        
        # è¿ç§»æ•°æ®
        migrated, errors = await migrate_from_json(conn)
        
        # éªŒè¯ç»“æœ
        await verify_migration(conn)
        
        # å…³é—­è¿æ¥
        await conn.close()
        
        logger.info("ğŸ‰ æ•°æ®è¿ç§»å®Œæˆï¼")
        logger.info(f"ğŸ“Š è¿ç§»ç»Ÿè®¡: æˆåŠŸ {migrated} æ¡ï¼Œå¤±è´¥ {errors} æ¡")
        
    except Exception as e:
        logger.error(f"âŒ è¿ç§»è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

# HTTPæœåŠ¡å™¨ç”¨äºCloud Run
from fastapi import FastAPI
import uvicorn

app = FastAPI()

migration_status = {"completed": False, "success": False, "message": "", "details": {}}

@app.get("/")
async def root():
    return {"message": "Migration service ready", "status": migration_status}

@app.post("/migrate")
async def migrate():
    """è§¦å‘è¿ç§»"""
    try:
        logger.info("ğŸš€ å¼€å§‹Cloud SQLæ•°æ®è¿ç§»...")
        
        # è¿æ¥æ•°æ®åº“
        logger.info("è¿æ¥Cloud SQLæ•°æ®åº“...")
        conn = await asyncpg.connect(DATABASE_URL)
        logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸï¼")
        
        # åˆ›å»ºè¡¨ç»“æ„
        await create_database_tables(conn)
        
        # è¿ç§»æ•°æ®
        migrated, errors = await migrate_from_json(conn)
        
        # éªŒè¯ç»“æœ
        await verify_migration(conn)
        
        # å…³é—­è¿æ¥
        await conn.close()
        
        migration_status.update({
            "completed": True,
            "success": True,
            "message": "Migration completed successfully",
            "details": {"migrated": migrated, "errors": errors}
        })
        
        logger.info("ğŸ‰ æ•°æ®è¿ç§»å®Œæˆï¼")
        return migration_status
        
    except Exception as e:
        error_msg = f"Migration failed: {str(e)}"
        logger.error(f"âŒ {error_msg}")
        migration_status.update({
            "completed": True,
            "success": False,
            "message": error_msg,
            "details": {}
        })
        return migration_status

@app.get("/health")
async def health():
    return {"status": "healthy"}

@app.get("/status")
async def status():
    return migration_status

if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦æœ‰å¯åŠ¨å‚æ•°å†³å®šè¿è¡Œæ¨¡å¼
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "--direct":
        # ç›´æ¥è¿è¡Œè¿ç§»
        asyncio.run(main())
    else:
        # å¯åŠ¨HTTPæœåŠ¡å™¨
        port = int(os.environ.get("PORT", 8080))
        logger.info(f"å¯åŠ¨HTTPæœåŠ¡å™¨ï¼Œç«¯å£: {port}")
        uvicorn.run(app, host="0.0.0.0", port=port) 